{
  "content": "Structure Learning of Probabilistic Graphical Models: A Comprehensive Survey Yang Zhou Michigan State University Nov 2007\nContents 1 Graphical Models 3 1.1 Introduction . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 3 1.2 Preliminaries . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 3 1.3 Undirected Graphical Models . . . . . . . . . . . . . . . . . . . . 5 1.3.1 Markov Random Field . . . . . . . . . . . . . . . . . . . . 5 1.3.2 Gaussian Graphical Model . . . . . . . . . . . . . . . . . . 6 1.4 Directed Graphical Models . . . . . . . . . . . . . . . . . . . . . 6 1.4.1 Conditional Probability Distribution . . . . . . . . . . . . 7 1.5 Other Graphical Models . . . . . . . . . . . . . . . . . . . . . . . 9 1.6 Network Topology . . . . . . . . . . . . . . . . . . . . . . . . . . 10 1.7 Structure Learning of Graphical Models . . . . . . . . . . . . . . 11 2 Constraint-based Algorithms 12 2.1 The SGS Algorithm . . . . . . . . . . . . . . . . . . . . . . . . . 12 2.2 The PC Algorithm . . . . . . . . . . . . . . . . . . . . . . . . . . 13 2.3 The GS Algorithm . . . . . . . . . . . . . . . . . . . . . . . . . . 14 3 Score-based Algorithms 16 3.1 Score Metrics . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 17 3.1.1 The MDL Score . . . . . . . . . . . . . . . . . . . . . . . 17 3.1.2 The BDe Score . . . . . . . . . . . . . . . . . . . . . . . . 18 3.1.3 Bayesian Information Criterion (BIC) . . . . . . . . . . . 19 3.2 Search for the Optimal Structure . . . . . . . . . . . . . . . . . . 21 3.2.1 Search over Structure Space . . . . . . . . . . . . . . . . . 21 3.2.2 Search over Ordering Space . . . . . . . . . . . . . . . . . 25 4 Regression-based Algorithms 27 4.1 Regression Model . . . . . . . . . . . . . . . . . . . . . . . . . . . 27 4.2 Structure Learning through Regression . . . . . . . . . . . . . . . 30 4.2.1 Likelihood Objective . . . . . . . . . . . . . . . . . . . . . 30 4.2.2 Dependency Objective . . . . . . . . . . . . . . . . . . . . 31 4.2.3 System-identiﬁcation Objective . . . . . . . . . . . . . . . 33 4.2.4 Precision Matrix Objective . . . . . . . . . . . . . . . . . 34 4.2.5 MDL Objective . . . . . . . . . . . . . . . . . . . . . . . . 35 1\n5 Hybrid Algorithms and Others 36 5.1 Hybrid Algorithms . . . . . . . . . . . . . . . . . . . . . . . . . . 36 5.2 Other Algorithms . . . . . . . . . . . . . . . . . . . . . . . . . . . 37 5.2.1 Clustering Approaches . . . . . . . . . . . . . . . . . . . . 37 5.2.2 Boolean Models . . . . . . . . . . . . . . . . . . . . . . . . 37 5.2.3 Information Theoretic Based Approach . . . . . . . . . . 37 5.2.4 Matrix Factorization Based Approach . . . . . . . . . . . 37 2\nChapter 1 Graphical Models 1.1 Introduction Probabilistic graphical models combine the graph theory an d probability theory to give a multivariate statistical modeling. They provide a uniﬁed description of uncertainty using probability and complexity using the g raphical model. Es- pecially, graphical models provide the following several u seful properties: •Graphical models provide a simple and intuitive interpreta tion of the structures of probabilistic models. On the other hand, they can be used to design and motivate new models. •Graphical models provide additional insights into the prop erties of the model, including the conditional independence properties . •Complex computations which are required to perform inferen ce and learn- ing in sophisticated models can be expressed in terms of grap hical manip- ulations, in which the underlying mathematical expression s are carried along implicitly. The graphical models have been applied to a large number of ﬁe lds, includ- ing bioinformatics, social science, control theory, image processing, marketing analysis, among others. However, structure learning for gr aphical models re- mains an open challenge, since one must cope with a combinato rial search over the space of all possible structures. In this paper, we present a comprehensive survey of the exist ing structure learning algorithms. 1.2 Preliminaries We will ﬁrst deﬁne a set of notations which will be used throug hout this paper. We represent a graph as G=∝a\\}bracketle{tV,E∝a\\}bracketri}htwhereV={vi}is the set of nodes in the graph and each node corresponds to a random variable xi∈X.E={(vi,vj) : 3\ni∝\\e}atio\\slash=j}is the set of edges. In a directed graph, if there is an edge Ei,jfromvito vj, thenviis a parent of node vjandvjis a child of node vi. If there is no cycle in a directed graph, we call it a Directed Acyclic Graph (DAG) . The number of nodes and number of edges in a graph are denoted by |V|and|E|respectively. π(i) is used to represent all the parents of node viin a graph. U={x1,···,xn} denotes the ﬁnite set of discrete random variables where eac h variableximay take on values from a ﬁnite domain. Val(xi) denotes the set of values that variableximay attain, and|xi|=|Val(xi)|denotes the cardinality of this set. In probabilistic graphical network, the Markov blanket ∂vi[Pearl, 1988] of a nodeviis deﬁned to be the set of nodes in which each has an edge to vi, i.e., all vjsuch that (vi,vj)∈E. The Markov assumption states that in a probabilistic graphicalnetwork, everysetofnodesinthenetworkiscondi tionallyindependent ofviwhen conditioned on its Markov blanket ∂vi. Formally, for distinct nodes viandvk, P(vi|∂vi∩vk) =P(vi|∂vi) The Markov blanket of a node gives a localized probabilistic interpretation of the node since it identiﬁes all the variables that shield oﬀ t he node from the rest of the network, which means that the Markov blanket of a n ode is the only information necessary to predict the behavior of that n ode. A DAG Gis an I-Map of a distribution Pif all the Markov assumptions implied by Gare satisﬁed by P. Theorem 1.2.1. (Factorization Theorem) IfGis an I-Map of P, then P(x1,···,xn) =∏ iP(xi|xπ(i)) According to this theorem, we can represent Pin a compact way when G is sparse such that the number of parameter needed is linear i n the number of variables. This theorem is true in the reverse direction. The setXis d-separated from set Ygiven setZif all paths from a node in Xto a node in Yare blocked given Z. The graphical models can essentially be divided into two gro ups: directed graphical models and undirected graphical models. X2 X9X1 Figure 1.1: An Ising model with 9 nodes. 4\n1.3 Undirected Graphical Models 1.3.1 Markov Random Field A Markov Random Field (MRF) is deﬁned as a pair M=∝a\\}bracketle{tG,Φ∝a\\}bracketri}ht. HereG= ∝a\\}bracketle{tV,E∝a\\}bracketri}htrepresents an undirected graph, where V={Vi}is the set of nodes, each of which corresponds to a random variable in X;E={(Vi,Vj) :i∝\\e}atio\\slash=j} represents the set of undirected edges. The existence of an e dge{u,v}indicates the dependency of the random variable uandv. Φ is a set of potential functions (also called factors or clique potentials) associated with the maximal cliques in the graphG. Each potential function φc(·) has the domain of some clique c inG, and is a mapping from possible joint assignments (to the ele ments ofc) to non-negative real values. A maximal clique of a graph is a f ully connected sub-graph that can not be further extended. We use Cto represent the set of maximal cliques in the graph. φcis the potential function for a maximal cliquec∈C. The joint probability of a conﬁguration xof the variables Vcan be calculated as the normalized product of the potential fun ction over all the maximal cliques in G: P(x) =∏text c∈Cφc(xc)∑text x′ c∏text c∈Cφc(xc) wherexcrepresents the current conﬁguration of variables in the max imal clique c,x′ crepresents any possible conﬁguration of variable in the max imal clique c. In practice, a Markov network is often conveniently express ed as a log-linear model, given by P(x) =exp(∑text c∈Cwcφc(xc)) ∑text x∈Xexp(∑text c∈Cwcφc(xc)) In the above equation, φcare feature functions from some subset of Xto real values,wcare weights which are to be determined from training samples . A log- linear model can provide more compact representations for a ny distributions, especially when the variables have large domains. This repr esentation is also convenient in analysis because its negative log likelihood is convex. However, evaluating the likelihood or gradient of the likelihood of a model requires in- ference in the model, which is generally computationally in tractable due to the diﬃculty in calculating the partitioning function. The Ising model is a special case of Markov Random Field. It co mes from statistical physics, where each node represents the spin of a particle. In an Ising model, the graph is a grid, so each edge is a clique. Each node in the Ising model takes binary values {0,1}. The parameters are θirepresenting the external ﬁeld on particle i, andθijrepresenting the attraction between particles 5\niandj.θij= 0 ifiandjare not adjacent. The probability distribution is: p(x|θ) = exp ∑ i<jθijxixj+∑ iθixi=−A(θ)  =1 Z(θ)exp ∑ i<jθijxixj+∑ iθixi  whereZ(θ) is the partition function. 1.3.2 Gaussian Graphical Model AGaussian Graphical Model (GGM) models the Gaussian property of multi- variate in an undirected graphical topology. Assuming that there arenvariables and all variables are normalized so that each of them follows a standard Gaus- sian distribution. We use X= (x1,···,xn) to represent the n×1 column matrix. In a GGM, the variables Xare assumed to follow a multivariate Gaus- sian distribution with covariance matrix Σ, P(X) =1 (2π)n 2|Σ|1 2exp(g −1 2X⊤Σ−1X)g In a Gaussian Graphical Model, the existence of an edge betwe en two nodes indicates that these two nodes are not conditionally indepe ndent given other nodes. Matrix Ω = Σ−1is called the precision matrix . The non-zeros elements in the precision matrix correspond to the edges in the Gaussi an Graphical Model. 1.4 Directed Graphical Models The most commonly used directed probabilistic graphical mo del is Bayesian Network [Pearl, 1988], which is a compact graphical represe ntation of joint distributions. A Bayesian Network exploits the underlying conditional inde- pendencies in the domain, and compactly represent a joint di stribution over variables by taking advantages of the local conditional ind ependence structures. A Bayesian network B=∝a\\}bracketle{tG,P∝a\\}bracketri}htis made of two components: a directed acyclic graph (DAG) Gwhose nodes correspond to the random variables, and a set ofconditional probabilistic distributions (CPD),P(xi|xπ(i)), which describe the statistical relationship between each node iand its parents π(i). In a CPD, for any speciﬁc conﬁguration of xπ(i), the sum over all possible values of xiis 1, ∑ xi∈Val(xi)P(xi|xπ(i)) = 1. In the continuous case, ∫display xi∈Val(xi)P(xi|xπ(i))dxi= 1 6\nwhereP(xi|xπ(i)) is the conditional density function. The conditional in- dependence assumptions together with the CPDs uniquely det ermine a joint probability distribution via the chain rule : P(x1,···,xn) =n∏ i=1P(xi|xπ(i)) Figure 1.2: A Bayesian network for detecting credit-card fr aud. Arcs indicate the causal relationship. The local conditional probabilit y distributions associ- ated with a node are shown next to the node. The asterisk indic ates any value for that variable. Figure excerpted from [Heckerman et al., 1995]. 1.4.1 Conditional Probability Distribution The CPDs may be represented in diﬀerent ways. The choice of th e represen- tation is critical because it speciﬁes the intrinsic nature of the conditional de- pendencies as well as the number of parameters needed for thi s representation. Here we describe some diﬀerent types of CPDs. Table CPDs In the discrete case, the CPDs can be simply represented as a t able in which eachrowcorrespondstoaspeciﬁcconﬁgurationofanodeandi tsparents, aswell as the corresponding conditional probability of this conﬁg uration [Heckerman et al., 1995]. The table CPDs are advantageous in that they ar e simple and clear, but the size of the table CPDs will grow exponentially with the increase in the number of parents and the number of values that each nod e can take. 7\nTree CPDs The tree CPDs try to exploit the context speciﬁc information (CSI), i.e., the distribution over the values of a node does not depend on the v alue of some subset of its parents given the value of the other parents [Bo utilier et al., 1996]. In a tree CPD, each interior vertex represents the splits on t he value of some parent vertices, and each leaf represents a probability con ditioned on a speciﬁc conﬁguration along the path originated from the root. The tr ee CPDs usually require a substantially smaller number of parameters than t able CPDs when CSI holds in many places of the Bayesian network. Softmax CPDs The softmax CPDs approximates the dependency of a discrete v ariablexion its parentsxπ(i)by a linear threshold function Segal [2004]. In this case, th e value of each node is determined based on the sum of the contributio ns of the values of all its parents, i.e., the eﬀect of π(i) on nodeitaking on a value xican be summarized via a linear function: fxi(xπ(i)=|π(i)|∑ j=1wxi,jxπ(i)(j) In the above equation, each weight wxi,jrepresents the contribution of the jth parent to the value of the target node i. Given the contribution function f,a common choice of how the probability of xidepends on fxi(xπ(i)) is thesoftmax distribution, which is the standard extension of the binary logistic conditional distribution to the multi-class case: P(xi|xπ(i)) =exp(fxi(xπ(i)))∑text xi∈Val(xi)exp(fxi(xπ(i))) Gaussian CPDs In many cases the random variables are continuous with assoc iated density functions. A common choice of the density function is Gaussi an distribution or Normal distribution t∼N(µ,σ2): P(xi=t) =N(µ,σ2) =1√ 2πσexp(g(t−µ)2 2σ2)g The Gaussian CPDs are often incorporated in the table or tree CPDs, in which the parameters muandσof the Gaussian distribution are determined by the conﬁguration of node is parents. 8\nSigmoid CPDs The Sigmoid Belief Networks (SBN) [Neal, 1992, Titov and Hen derson, 2007] has the CPD in the form: P(xi= 1|xπ(i)) =σ(∑ j∈π(i)Jijxj) whereσ(·) denotes the logistic sigmoid function, and Jijis the weight from jto i. Probability Formulas CPDs In a Relational Bayesian Network (RBN) [Jaeger, 1997, 2001] , all variables take binary values. Each root node ihas probability θi∈[0,1] to be 1. For each non-root node, the probability to taking value 1 is a combina tion function of the values of all its parents. A commonly used combination funct ion is the noisy-or function which is deﬁned as noisy-or( I) = 1−πp∈I(1−p) whereIis a multiset of probabilities. 1.5 Other Graphical Models •Dependency Networks : In[Heckermanetal.,2000], theauthorsproposeda probabilistic graphical model named Dependency Networks, which can be considered as combination of Bayesian network and Markov ne twork. The graph of a dependency network, unlike a Bayesian network, ca n be cyclic. The probability component of a dependency network, like a Ba yesian net- work, is a set of conditional distributions, one for each nod e given its parents. A dependency network is a pair ∝a\\}bracketle{tG,P∝a\\}bracketri}htwhereGis a cyclic directed graph andPis a set of conditional probability distributions. The pare nts of nodesπ(i) of nodeicorrespond to those variables that satisfy p(xi|xπ(i)) =p(xi|xV\\i) In other words, a dependency network is simply a collection o f conditional distributions that are deﬁned and built separately. In a spe ciﬁc context of sparse normal models, these would deﬁne a set of separate c onditional linear regressions in which xiis regressed to a small selected subset of other variables, each being determined separately. The independencies in a dependency network are the same as th ose of a Markov network with the same adjacencies. The authors prov ed that the Gibbs sampler applied to the dependency network will yie ld a joint distribution for the domain. The applications of dependenc y network in- clude probabilistic inference, collaborative ﬁltering an d the visualization of causal predictive relationships. 9\n•Module Networks : In [Segal et al., 2003], the authors proposed a mod- ule networks model for gene regulatory network constructio n. The basic structure is a Bayesian network. Each regulatory module is a set of genes that are regulated in concert by a shared regulation program that governs their behavior. A regulation program speciﬁes the behavior of the genes in the module as a function of the expression level of a small s et of regula- tors. By employing the Bayesian structure learning to the mo dules instead of genes, this algorithm is able to reduce the computational complexity signiﬁcantly. In [Toh and Horimoto, 2002] the authors proposed a model with the sim- ilar idea, yet they built a Gaussian Graphical Model instead of Bayesian networks, of module networks. In their study of the yeast (Sa ccharomyces cerevisiae) genes measured under 79 diﬀerent conditions, t he 2467 genes are ﬁrst classiﬁed into 34 clusters by a hierarchical cluste ring analysis [Ho- rimoto and Toh, 2001]. Then the expression levels of the gene s in each cluster are averaged for each condition. The averaged expre ssion proﬁle data of 34 clusters were subjected to GGM, and a partial corre lation co- eﬃcient matrix was obtained as a model of the genetic network . •Probabilistic Relational Models : A probabilistic relational model [Fried- man et al., 1999a] is a probabilistic description of the rela tional models, like the models in relational databases. A relational model consists of a set of classes and a set of relations. Each entity type is associa ted with a set of attributes. Each attribute takes on values in some ﬁxed doma in of values. Each relation is typed. The probabilistic relational model describes the relationships between entities and the properties of entit ies. The model consists of two components: the qualitative dependency str ucture which is a DAG, and the parameters associated with it. The dependen cy struc- ture is deﬁned by associating with each attribute and its par ents, which is modeled as conditional probabilities. 1.6 Network Topology Twoclassesofnetworkarchitecturesareofspecialinteres ttosystembiology[Ki- tano, 2002]: the small world networks [Watts and Strogatz, 1998] and scall-free power law networks [Barabasi and Albert, 1999]. Small world networks are characterized by high clustering coeﬃcients and small diam eters. The clus- tering coeﬃcient C(p) is deﬁned as follows. Suppose that a vertex vhaskv neighbors; then at most kv(kv−1)/2 edges can exist between them (this occurs when every neighbor of vis connected to every other neighbor of v). LetCvde- note the fraction of these allowable edges that actually exi st, then the clustering coeﬃcientCis deﬁned as the average of Cvover allv. These properties reﬂect the existence of local building blo cks together with long-range connectivity. Most nodes in small world network s have approxi- mately the same number of links, and the degree distribution P(k) decays ex- 10\nponentially for large k. Compared to small world networks, the scale-free power law networks have smaller clustering coeﬃcients and large d iameters. Most nodes in the scale-free networks are connected to a few neigh bors, and only a small number of nodes, which is often called “hubs”, are conn ected to a large number of nodes. This property is reﬂected by the power law fo r the degree distribution P(k)∼k−v. Previous studies have found that a number of network structu res appear to have structures between the small-world network and the sca le-free network. In fact, these networks behave more like hierarchical scale-free [Han et al., 2004, Jeong et al., 2000, Lukashin et al., 2003, Basso et al., 2005, Bhan et al., 2002, Ravasz et al., 2002]. Nodes within the networks are ﬁrst grou ped into modules, whose connectivity is more like the small worlds network. Th e grouped modules are then connected into a large network, which follows the de gree distribution that is similar to that of the scale-free network. 1.7 Structure Learning of Graphical Models Therearethreemajorapproachesofexistingstructurelear ningmethods: constraint- based approaches ,score-based approaches andregression-based approaches. Constraint-based approaches ﬁrst attempt to identify a set of conditional independence properties, and then attempt to identify the n etwork structure that best satisﬁes these constraints. The drawback with the constraints based approaches is that it is diﬃcult to reliably identify the con ditional independence properties and to optimize the network structure [Margarit is, 2003]. Plus, the constraints-based approaches lack an explicit objective f unction and they do not try to directly ﬁnd the globally optimal structure. So th ey do not ﬁt in the probabilistic framework. Score-based approaches ﬁrst deﬁne a score function indicat ing how well the network ﬁts the data, then search through the space of all pos sible structures to ﬁnd the one that has the optimal value for the score functio n. Problem with this approach is that it is intractable to evaluate the score for all structures, so usuallyheuristics, likegreedysearch, areusedtoﬁndthes ub-optimalstructures. Regression-based approaches are gaining popularity in rec ent years. Algorithms in this category are essentially optimization problems whi ch guarantees global optimum for the objective function, and have better scalabi lity. Regression-based approaches are gaining popularity in rec ent years. Algo- rithms in this category are essentially optimization probl ems which guarantees global optimum for the objective function, and have better s calability. 11\nChapter 2 Constraint-based Algorithms The constraint-based approaches [Tsamardinos et al., 2006 , Juliane and Ko- rbinian, 2005, Spirtes et al., 2000, Wille et al., 2004, Marg aritis, 2003, Margari- tis and Thrun, 1999] employ the conditional independence te sts to ﬁrst identify a set of conditional independence properties, and then atte mpts to identify the network structure that best satisﬁes these constraints. Th e two most popular constraint-based algorithm are the SGS algorithm and PC alg orithm [Tsamardi- nos et al., 2006], both of which tries to d-separate all the va riable pairs with all the possible conditional sets whose sizes are lower than a gi ven threshold. One problem with constraint-based approaches is that they a re diﬃcult to reliably identify the conditional independence propertie s and to optimize the network structure [Margaritis, 2003]. The constraint-bas ed approaches lack an explicit objective function and they do not try to directly ﬁ nd the global struc- turewithmaximumlikelihood. Sotheydonotﬁtintheprobabi listicframework. 2.1 The SGS Algorithm The SGS algorithm (named after Spirtes, Glymour and Scheine s) is the most straightforwardconstraint-basedapproachforBayesiann etworkstructurelearn- ing. It determines the existence of an edge between every two node variables by conducting a number of independence tests between them cond itioned on all the possible subsets of other node variables. The pseudo code of the SGS algorithm is listed in Algorithm 1. After slight modiﬁcation, SGS algo rithm can be used to learn the structure of undirected graphical models (Mark ov random ﬁelds). The SGS algorithm requires that for each pair of variables ad jacent inG, all possible subsets of the remaining variables should be co nditioned. Thus this algorithm is super-exponential in the graph size (number of vertices) and thus unscalable. The SGS algorithm rapidly becomes infeasible w ith the increase of the vertices even for sparse graphs. Besides the computat ional issue, the 12\nAlgorithm 1 SGS Algorithm 1:Build a complete undirected graph Hon the vertex set V. 2:For each pair of vertices iandj, if there exists a subset SofV\\{i,j}such thatiandjare d-separated given S, remove the edge between iandjfrom G. 3:LetG′be the undirected graph resulting from step 2. For each tripl e of verticesi,jandksuch that the pair iandjand the pair jandkare each adjacent in G′(written as i−j−k) but the pair iandkare not adjacent inG′, orienti−j−kasi→j←kif and only if there is no subset Sof {j}∪V\\{i,j}that d-separate iandk. 4:repeat 5:Ifi→j,jandkare adjacent, iandkare not adjacent, and there is no arrowhead at j, then orient j−kasj→k. 6:If there is a directed path from itoj, and an edge between iandj, then orienti−jasi→j. 7:untilno more edges can be oriented. SGS algorithm has problems of reliability when applied to sa mple data, because determination of higher order conditional independence re lations from sample distribution is generally less reliable than is the determi nation of lower order independence relations. 2.2 The PC Algorithm The PC algorithm (named after Peter Spirtes and Clark Glymou r) is a more eﬃcient constraint-based algorithm. It conducts independ ence tests between all the variable pairs conditioned on the subsets of other node v ariables that are sorted by their sizes, from small to large. The subsets whose sizes are larger than a given threshold are not considered. The pseudo-code o f the PC algorithm is given in Algorithm 2. We use N(i) to denote the adjacent vertices to vertex iin a directed acyclic graph G. The complexity of the PC algorithm for a graph Gis bounded by the largest degree inG. Suppose dis the maximal degree of any vertex and nis the number of vertices. In the worst case the number of condition al independence tests required by the PC algorithm is bounded by 2(gn 2)gd∑ i=1(gn−1 i)g The PC algorithm can be applied on graphs with hundreds of nod es. How- ever, it is not scalable if the number of nodes gets even large r. 13\nAlgorithm 2 PC Algorithm 1:Build a complete undirected graph Gon the vertex set V. 2:n = 0. 3:repeat 4:repeat 5:Select an ordered pair of vertices iandjthat are adjacent in Gsuch thatN(i)\\{j}has cardinality greater than or equal to n, and a subset SofN(i)\\{j}of cardinality n, and ifiandjare d-separated given S delete edge i−jfromGand record SinSepset(i,j) andSepset(j,i). 6:untilallorderedpairsofadjacentvariables iandjsuchthatN(i)\\{j}has cardinality greater than or equal to nand all subsets SofN(i)\\{j}of cardinality nhave been tested for d-separation. 7:n = n + 1. 8:untilfor each ordered pair of adjacent vertices iandj,N(i)\\{j}is of cardinality less than n. 9:For each triple of vertices i,jandksuch that the pair i,jand the pair j,kare each adjacent in Gbut the pair i,kare not adjacent in G, orient i−j−kasi→j←kif and only if jis not inSepset(i,k). 10:repeat 11:Ifi→j,jandkare adjacent, iandkare not adjacent, and there is no arrowhead at j, then orient j−kasj→k. 12:If there is a directed path from itoj, and an edge between iandj, then orienti−jasi→j. 13:untilno more edges can be oriented. 2.3 The GS Algorithm BoththeSGSandPCalgorithmstartfromacompletegraph. Whe nthenumber of nodes in the graph becomes very large, even PC algorithm wi ll be intractable due to the large combinatorial space. In Margaritis and Thrun [1999], the authors proposed a Grow- Shrinkage (GS) algorithm to address the large scale network structure learning problem by exploring the sparseness of the graph. The GS algorithm us e two phases to estimate a superset of the Markov blanket ˆ∂(j) for nodejas in Algorithm 3. In the pseudo code, i↔Sjdenotes that node iandjare dependent conditioned on setS. Algorithm 3 includes two phases to estimate the Markov blank et. In the “grow” phase, variables are added to the Markov blanket ˆ∂(j) sequentially using aforwardfeatureselectionprocedure, whichoftenresults inasupersetofthereal Markov blanket. In the “shrinkage” phase, variables are del eted from the ˆ∂(j) if they are independent from the target variable conditioned o n the subset of other variables in ˆ∂(j). Given the estimated Markov blanket, the algorithm then tr ies to identify both the parents and children for each variable a s in Algorithm 4. In[MargaritisandThrun,1999], theauthorsfurtherdevelo pedarandomized version of the GS algorithm to handle the situation when 1) th e Markov blanket 14\nAlgorithm 3 GS: Estimating the Markov Blanket 1:S←Φ. 2:while∃j∈V\\{i}such thatj↔Sido 3:S←S∪{j}. 4:end while 5:while∃j∈Ssuch thatj/notarrowbothS\\{i}ido 6:S←S\\{j}. 7:end while 8:ˆ∂(i)←S Algorithm 4 GS Algorithm 1:Compute Markov Blankets : for each vertex i∈Vcompute the Markov blanket∂(i). 2:Compute Graph Structure : for alli∈Vandj∈∂(i), determine jto be a direct neighbor of iifiandjare dependent given Sfor allS⊆TwhereT is the smaller of ∂(i)\\{j}and∂(j)\\{i}. 3:Orient Edges : for alli∈Vandj∈∂(i), orientj→iif there exists a variablek∈∂(i)\\{∂(j)∪{j}}such thatjandkare dependent given S∪{i}for allS⊆UwhereUis the smaller of ∂(j)\\{k}and∂(k)\\{j}. 4:repeat 5:Compute the set of edges C={i→jsuch thati→jis part of a cycle}. 6:Remove the edge in Cthat is part of the greatest number of cycles, and put it inR. 7:untilthere is no cycle exists in the graph. 8:Reverse Edges : Insert each edge from Rin the graph, reversed. 9:Propagate Directions : for alli∈Vandj∈∂(i) such that neither j→inor i→j, execute the following rule until it no longer applies: if th ere exists a directed path from itoj, orienti→j. is relatively large, 2) the number of training samples is sma ll compared to the number of variables, or there are noises in the data. In a sparse network in which the Markov blankets are small, th e complexity of GS algorithm is O(n2) wherenis the number of nodes in the graph. Note that GS algorithm can be used to learn undirected graphical s tructures (Markov Random Fields) after some minor modiﬁcations. 15\nChapter 3 Score-based Algorithms Score-basedapproaches[Heckermanetal.,1995,Friedmane tal.,1999b,Hartemink et al., 2001] ﬁrst posit a criterion by which a given Bayesian network structure can be evaluated on a given dataset, then search through the s pace of all possi- ble structures and tries to identify the graph with the highe st score. Most of the score-based approaches enforce sparsity on the learned str ucture by penalizing the number of edges in the graph, which leads to a non-convex o ptimization problem. Score-based approaches are typically based on wel l established statis- tical principles such as minimum description length (MDL) [ Lam and Bacchus, 1994, Friedman and Goldszmidt, 1996, Allen and Greiner, 200 0] or the Bayesian score. The Bayesian scoring approaches was ﬁrst developed i n [Cooper and Herskovits, 1992], and then reﬁned by the BDe score [Heckerm an et al., 1995], which is now one the of best known standards. These scores oﬀe r sound and well motivated model selection criteria for Bayesian network st ructure. The main problem with score based approaches is that their associate d optimization prob- lems are intractable. That is, it is NP-hard to compute the op timal Bayesian network structure using Bayesian scores [Chickering, 1996 ]. Recent researches haveshownthatforlargesamples, optimizingBayesiannetw orkstructureisNP- hard for all consistent scoring criteria including MDL, BIC and the Bayesian scores [Chickering et al., 2004]. Since the score-based app roaches are not scal- able for large graphs, they perform searches for the locally optimal solutions in the combinatorial space of structures, and the local optima l solutions they ﬁnd could be far away from the global optimal solutions, especia lly in the case when the number of sample conﬁgurations is small compared to the n umber of nodes. The space of candidate structures in scoring based approach es is typically restricted to directed models (Bayesian networks) since th e computation of typi- cal score metrics involves computing the normalization con stant of the graphical model distribution, which is intractable for general undir ected models [Pollard, 1984]. Estimation of graph structures in undirected models has thus largely been restricted to simple graph classes such as trees [Chow e t al., 1968], poly- trees [Chow et al., 1968] and hypertrees [Srebro, 2001]. 16\n3.1 Score Metrics 3.1.1 The MDL Score The Minimum Description Length (MDL) principle [Rissanen, 1989] aims to minimize the space used to store a model and the data to be enco ded in the model. In the case of learning Bayesian network Bwhich is composed of a graph Gand the associated conditional probabilities PB, the MDL criterion requires choosing a network that minimizes the total description len gth of the network structure and the encoded data, which implies that the learn ing procedure bal- ances the complexity of the induced network with the degree o f accuracy with which the network represents the data. Since the MDL score of a network is deﬁned as the total descrip tion length, it needs to describe the data U, the graph structure Gand the conditional probability Pfor a Bayesian network B=∝a\\}bracketle{tG,P∝a\\}bracketri}ht. To describe U, we need to store the number of variables n and the cardinalit y of each variable xi. We can ignore the description length of Uin the total description length since Uis the same for all candidate networks. To describe the DAG G, we need to store the parents π(i) of each variable xi. This description includes the number of parents |π(i)|and the index of the setπ(i) in some enumeration of all(n |π(i)|) sets of this cardinality. Since the number of parents |π(i)|can be encoded in log nbits, and the indices of all parents of node ican be encoded in log(n π(i)) bits, the description length of the graph structure Gis DLgraph(G) =∑ i(g logn+log(gn |π(i)|)g)g (3.1) To describe the conditional probability Pin the form of CPD, we need to store the parameters in each conditional probability table. The n umber of param- eters used for the table associated with xiis|π(i)|(|xi|−1). The description length of these parameters depends on the number of bits used for each numeric parameter. A usual choice is 1 /2logN[Friedman and Goldszmidt, 1996]. So the description length for xi’s CPD is DLtab(xi) =1 2|π(i)|(|xi|−1)logN To describe the encoding of the training data, we use the prob ability measure deﬁned by the network Bto construct a Huﬀman code for the instances in D. In this code, the length of each codeword depends on the proba bility of that instance. According to [Cover and Thomas, 1991], the optima l encoding length for instance xican be approximated as −logPxi. So the description length of 17\nthe data is DLdata(D|B) =−N∑ i=1logP(xi) =−∑ i∑ xi,xπ(i)#(xi,xπ(i))logP(xi|xπ(i)). In the above equation, ( xi,xπ(i)) is a local conﬁguration of variable xiand its parents, #( xi,xπ(i)) is the number of the occurrence of this conﬁguration in the training data. Thus the encoding of the data can be deco mposed as the sum of terms that are “local” to each CPD, and each term only de pends on the counts #(xi,xπ(i)). IfP(xi|xπ(i)) is represented as a table, then the parameter values that mi ni- mizeDLdata(D|B) areθxi|xπ(i)=ˆP(xi|xπ(i)) [Friedman and Goldszmidt, 1998]. Ifweassignparametersaccordingly, then DLdata(D|B)canberewritteninterms of conditional entropy as N∑text iH(xi|xπ(i)), where H(X|Y) =−∑ x,yˆP(x,y)logˆP(x|y) istheconditionalentropyof XgivenY. Thenewformulaprovidesaninformation- theoretic interpretation to the representation of the data : it measures how many bits are necessary to encode the values of xionce we know xπ(i). Finally, by combining the description lengths above, we get the total de- scription length of a Bayesian network as DL(G,D) =DLgraph(G)+∑ iDLtab(xi)+N∑ iH(xi|xπ(i)) (3.2) 3.1.2 The BDe Score The Bayesian score for learning Bayesian networks can be der ived from methods of Bayesian statistics, one important example of which is BD e score [Cooper and Herskovits, 1992, Heckerman et al., 1995]. The BDe score is p roportional to the posterior probability of the network structure given the da ta. LetGhdenote the hypothesis that the underlying distribution satisﬁes the i ndependence relations encoded in G. Let Θ Grepresent the parameters for the CPDs qualifying G. By Bayes rule, the posterior probability P(Gh|D) is P(Gh|D) =P(D|Gh)P(Gh) P(D) In the above equation, 1 /P(D) is the same for all hypothesis, and thus we denote this constant as α. The term P(D|Gh) is the probability given the network structure, and P(Gh) is the prior probability of the network structure. They are computed as follows. 18\nThe prior over the network structures is addressed in severa l literatures. In [Heckerman et al., 1995], this prior is chosen as P(Gh)∝α∆(G,G′), where ∆(G,G′) is the diﬀerence in edges between Gand a prior network structure G′, and 0<a<1 is the penalty for each edge. In [Friedman and Goldszmidt, 1 998], this prior is set as P(Gh)∝2−DLgraph(G), whereDLgraph(G) is the description length of the network structure G, deﬁned in Equation 3.1. The evaluation of P(D|Gh) needs to consider all possible parameter assign- ments toG, namely P(D|Gh) =∫display P(D|ΘG,Gh)P(ΘG|Gh)dΘG, (3.3) whereP(D|ΘG,Gh) is the probability of the data given the network structure and parameters. P(ΘG|Gh) is the prior probability of the parameters. Under the assumption that each distribution P(xi|xπ(i)) can be learned independently of all other distributions [Heckerman et al., 1995], Equati on 3.3 can be written as P(D|Gh) =∏ i∏ π(i)∫display∏ xiθN(xi,xπ(i)) i,π(i)P(Θi,π(i)|Gh)dΘi,π(i). Note that this decomposition is analogous to the decomposit ion in Equation 3.2. In [Heckerman et al., 1995], the author suggested that each m ultinomial distri- bution Θ i,π(i)takes aDirichlet prior , such that P(ΘX) =β∏ xθN′ xx whereN′ x:x∈Val(X) is a set of hyper parameters ,βis a normalization constant. Thus, the probability of observing a sequence of v alues ofXwith countsN(x) is ∫display∏ xθN(x) xP(ΘX|Gh)dΘX=Γ(∑text xN′(x)) Γ(∑text x(N′x+N(x)))∏ xΓ(N′ x+N(x)) Γ(N′x) where Γ(x) is theGamma function deﬁned as Γ(x) =∫display∞ 0tx−te−tdt The Gamma function has the following properties: Γ(1) = 1 Γ(x+1) =xΓ(x) If we assign each Θ i,π(i)a Dirichlet prior with hyperparameters Nthen P(D|Gh) =∏ i∏ π(i)Γ(∑text iN′ i,π(i)) Γ(∑text iN′ i,π(i)+N(π(i)))∏ xiΓ(N′ i,π(i)+N(i,π(i))) Γ(N′ i,π(i)) 19\n3.1.3 Bayesian Information Criterion (BIC) A natural criterion that can be used for model selection is th e logarithm of the relative posterior probability: logP(D,G) = logP(G)+logP(D|G) (3.4) Here the logarithm is used for mathematical convenience. An equivalent criterion that is often used is: log(gP(G|D) P(G0|D))g = log(gP(G) P(G0))g +log(gP(D|G) P(D|G0))g The ratioP(D|G)/P(D|G0) in the above equation is called Bayes factor [Kass and Raftery, 1995]. Equation 3.4 consists of two components : the log prior of the structure and the log posterior probability of the struc ture given the data. In the large-sample approximation we drop the ﬁrst term. Let us examine the second term. It can be expressed by margina lizing all the assignments of the parameters Θ of the network: logP(D|G) = log∫display ΘP(D|G,Θ)P(Θ|G)dΘ (3.5) In [Kass and Raftery, 1995], the authors proposed a Gaussian approximation forP(Θ|D,G)∝P(D|Θ,G)P(Θ|G) for large amounts of data. Let g(Θ)≡log(P(D|Θ,G)P(Θ|G)) We assume that ˜Θ is the maximum a posteriori (MAP) conﬁguration of Θ forP(Θ|D,G), which also maximizes g(Θ). Using the second degree Taylor series approximation of g(Θ) at˜Θ: g(Θ)≈g(˜Θ)−1 2(Θ−˜Θ)A(Θ−˜Θ)⊤ WhereAis the negative Hessian of g(Θ) at˜Θ. Thus we get P(Θ|D,G)∝P(D|Θ,G)P(Θ,G) ≈P(D|˜Θ,S)P(˜Θ|S)exp(g1 2(Θ−˜Θ)A(Θ−˜Θ)⊤)g (3.6) Soweapproximate P(Θ|D,G)asamultivariateGaussiandistribution. Plugging Equation 3.6 into Equation 3.5 and we get: logP(D|G)≈logP(D|˜Θ,G)+logP(˜Θ|G)+d 2log(2π)−1 2log|A|(3.7) wheredisthedimensionof g(Θ). Inourcaseitisthenumberoffreeparameters. Equation 3.7 is called a Laplace approximation , which is a very accurate approximation with relative error O(1/N) whereNis the number of samples in D[Kass and Raftery, 1995]. 20\nHowever, the computation of |A|is a problem for large-dimension models. We can approximate it using only the diagonal elements of the HessianA, in which case we assume independencies among the parameters. In asymptotic analysis, we get a simpler approximation of th e Laplace ap- proximation in Equation 3.7 by retaining only the terms that increase with the number of samples N: logP(D|˜Θ,G) increases linearly with N; log|A|in- creases asdlogN. And˜Θ can be approximated by the maximum likelihood conﬁguration ˜Θ. Thus we get logP(D|G)≈P(D|˜Θ,S)−d 2logN (3.8) Thisapproximationiscalledthe Bayesian Information Criterion (BIC)[Schwarz, 1978]. Note that the BIC does not depend on the prior, which me ans we can use the approximation without assessing a prior. The BIC app roximation can be intuitively explained: in Equation 3.8 , log P(D|˜Θ,G) measures how well the parameterized structure predicts the data, and ( d/2logN) penalizes the com- plexity of the structure. Compared to the Minimum Descripti on Length score deﬁned in Equation 3.2, the BIC score is equivalent to the MDL except term of the description length of the structure. 3.2 Search for the Optimal Structure Once the score is deﬁned, the next task is to search in the stru cture space and ﬁnd the structure with the highest score. In general, thi s is an NP-hard problem [Chickering, 1996]. Note that one important property of the MDL score or the Bayes ian score (when used with a certain class of factorized priors such as the BDe priors) is thedecomposability in presence of complete data, i.e., the scoring functions we discussed earlier can be decomposed in the following way: Score(G:D) =∑ iScore(xi|xπ(i):Nxi,xπ(i)) whereNxi,xπ(i)is the number of occurrences of the conﬁguration xi,xπ(i). The decomposability of the scores is crucial for score-base d learning of struc- tures. When searching the possible structures, whenever we make a modiﬁca- tion in a local structure, we can readily get the score of the n ew structure by re-evaluating the score at the modiﬁed local structure, whi le the scores of the rest part of the structure remain unchanged. Due to the large space of candidate structures, simple searc h would in- evitably leads to local maxima. To deal with this problem, ma ny algorithms were proposed to constrain the candidate structure space. H ere they are listed as follows. 21\nAlgorithm 5 Hill-climbing search for structure learning 1:Initialize a structure G′. 2:repeat 3:SetG=G′. 4:Generate the acyclic graph set Neighbor (G) by adding, removing or re- versing an edge in graph G. 5:Choose from Neighbor (G) the one with the highest score and assign to G′. 6:untilConvergence. 3.2.1 Search over Structure Space The simplest search algorithm over the structure is the gree dy hill-climbing search [Heckerman et al., 1995]. During the hill-climbing s earch, a series of modiﬁcationsofthelocalstructuresbyadding,removingor reversinganedgeare made, and the score of the new structure is reevaluated after each modiﬁcation. The modiﬁcations that increase the score in each step is acce pted. The pseudo- code of the hill-climbing search for Bayesian network struc ture learning is listed in Algorithm 5. Besides the hill-climbing search, many other heuristic sea rching methods have also been used to learn the structures of Bayesian netwo rks, including the simulated annealing [Chickering and Boutilier, 1996], bes t-ﬁrst search [Russel and Norvig, 1995] and genetic search [Larranaga et al., 1996 ]. A problem with the generic search procedures is that they do n ot exploit the knowledge about the expected structure to be learned. As a re sult, they need to search through a large space of candidate structures. For ex ample, in the hill- climbingstructuresearchinAlgorithm5,thesizeof Neighbor (G)isO(n2)where nisthenumberofnodesinthestructure. Sothealgorithmneed stocomputethe scores ofO(n2) candidate structures in each update (the algorithm also ne ed to check acyclicity of each candidate structure), which ren ders the algorithm unscalable for large structures. In [Friedman et al., 1999b], the authors proposed a Sparse Ca ndidate Hill Climbing (SCHC) algorithm to solve this problem. The SCHC al gorithm ﬁrst estimates the possible candidate parent set for each variab le and then use hill- climbing to search in the constrained space. The structure r eturned by the search can be used in turn to estimate the possible candidate parent set for each variable in the next step. The key in SCHC is to estimate the possible parents for each no de. Early works [Chow et al., 1968, Sahami, 1996] use mutual information to determine if there is an edge between two nodes: I(X;Y) =∑ x,yˆP(x,y)logˆP(x,y) ˆP(x)ˆP(y) whereˆP(·) is the observed frequencies in the dataset. A higher mutual in- 22\nformation indicates a stronger dependence between XandY. Yet this measure is not suitable be used to determine the existence of an edge b etween two nodes has problems because, for example, it does not consider the i nformation that we already learnt about the structure. Instead, Friedman et al . [1999b] proposed two other metrics to evaluate the dependency of two variable s. •The ﬁrst metric is based on an alternative deﬁnition of mutua l informa- tion. The mutual information between XandYis deﬁned as the distance between the joint distribution of ˆP(X,Y) and the distribution ˆP(X)ˆP(Y), which assumes the independency of the two variables: I(X;Y) =DKL( ˆP(X,Y)||ˆP(X)ˆP(Y)) whereDKL(P||Q) is theKullback-Leibler divergence deﬁned as: DKL(P(X)||Q(X)) =∑ XP(X)logP(X) Q(X) Under this deﬁnition, the mutual information measures the e rror we in- troduce if we assume the independency of XandY. During each step of the search process, we already have an estimation of the ne twork B. To utilize this information, similarly, we measure the disc repancy between the estimation PB(X,Y) and the empirical estimation ˆP(X,Y) as: DKL(P(X)||Q(X)) =∑ XP(X)logP(X) Q(X) One issue with this measure is that it requires to compute PB(Xi,Yi) for pairs of variables. When learning networks over large numbe r of variables this can be computationally expensive. However, one can eas ily approxi- mate these probabilities by using a simple sampling approac h. •The second measure utilizes the Markov property that each no de is in- dependent of other nodes given its Markov blanket. First the conditional mutual information is deﬁned as: I(X;Y|Z) =∑ ZˆP(Z)DKL(ˆP(X,Y|Z)||ˆP(X|Z)ˆP(Y|Z)). This metric measures the error that is introduced when assum ing the conditional independence of XandYgivenZ. Based upon this, another metric is deﬁned as: Mshield(Xi,Xj|B) =I(Xi;Xj|Xπ(i)) Note that using either of these two metrics for searching, at the beginning of the search, i.e.,B0is an empty network, the measure is equivalent to I(X;Y). 23\nLater iterations will incorporate the already estimated ne twork structure in choosing the candidate parents. Another problem with the hill-climbing algorithm is the sto pping criteria for the search. There are usually two types of stopping criteria : •Score-based criterion : the search process terminates when Score(Bt) = Score(Bt−1). In other words, the score of the network can no longer be increased by updating the network from candidate network sp ace. •Candidate-based criterion : the search process terminates when Ct i=Ct−1 i for alli, that is, the candidate space of the network remains unchang ed. Since the score is a monotonically increasing bounded funct ion, the score- based criterion is guaranteed to stop. The candidate-based criterion might enter a loop with no ending, in which case certain heuristics are ne eded to stop the search. There are four problems with the SCHC algorithm. First, the e stimation of the candidate sets is not sound (i.e., may not identify the tr ue set of parents), and it may take a number of iterations to converge to an accept able approx- imation of the true set of parents. Second, the algorithm nee ds a pre-deﬁned parameterk, the maximum number of parents allowed for any node in the net - work. Ifkis underestimated, there is a risk of discovering a suboptim al network. On the other hand, if kis overestimated, the algorithm will include unnecessary parents in the search space, thus jeopardizing the eﬃciency of the algorithm. Third, as already implied above, the parameter kimposes a uniform sparseness constraint on the network, thus may sacriﬁce either eﬃcienc y or quality of the algorithm. A more eﬃcient way to constrain the search space i s the Max-Min Hill-Climbing(MMHC)algorithm[Tsamardinosetal.,2006] , ahybridalgorithm which will be explained in Section 5.1. The last problem is th at the constraint of the maximum number of parents kwill conﬂict with the scale-free networks due to the existence of hubs (this problem exists for any algo rithm that imposes this constraint). Using the SCHC search, the number of candidate structures in each update is reduced from O(n2) toO(n) wherenis the number of nodes in the structure. Thus, the algorithm is capable to learn large-scale structu res with hundreds of nodes. The hill-climbing search is usually applied with multiple r estarts and tabu list [Cvijovicacute and Klinowski, 1995]. Multiple restar ts are used to avoid local optima, and the tabu list is used to record the path of th e search so as to avoid loops and local minima. To solve the problem of large candidate structure space and l ocal optima, some other algorithms are proposed as listed in the followin g. •In [Moore and keen Wong, 2003], the authors proposed a search strategy based on a more complex search operator called optimal reins ertion. In each optimal reinsertion, a target node in the graph is picke d and all arcs entering or exiting the target are deleted. Then a globally o ptimal com- bination of in-arcs and out-arcs are found and reinserted in to the graph 24\nsubject to some constraints. With the optimal reinsertion o peration de- ﬁned, the search algorithm generates a random ordering of th e nodes and applies the operation to each node in the ordering in turn. Th is proce- dure is iterated, each with a newly randomized ordering, unt il no change is made in a full pass. Finally, a conventional hill-climbin g is performed to relax the constraint of max number of parents in the optimal r einsertion operator. •In [Xiang et al., 1997], the authors state that with a class of domain models of probabilistic dependency network, the optimal st ructure can not be learned through the search procedures that modify a netwo rk structure onelinkatatime. Forexample,giventhe XORnodesthereisnobeneﬁtin adding any oneparent individually without the others and so single-link hill-climbing can make no meaningful progress. They propos e a multi- link lookahead search for ﬁnding decomposable Markov Netwo rks (DMN). This algorithm iterates over a number of levels where at leve li, the current network is continually modiﬁed by the best set of ilinks until the entropy decrement fails to be signiﬁcant. •Some algorithms identify the Markov blanket or parent sets b y either using conditional independency test, mutual information o r regression, then use hill-climbing search over this constrained candid ate structure space [Tsamardinos et al., 2006, Schmidt and Murphy, 2007]. These al- gorithms belong to the hybrid methods. Some of them are liste d in Sec- tion 5.1. 3.2.2 Search over Ordering Space TheacyclicityoftheBayesiannetworkimpliesan ordering propertyofthestruc- ture such that if we order the variables as ∝a\\}bracketle{tx1,···,xn∝a\\}bracketri}ht, each node xiwould have parents only from the set {x1,···,xi−1}. Fundamental observations [Buntine, 1991, Cooper and Herskovits, 1992] have shown that given an o rdering on the variables in the network, ﬁnding the highest-scoring netwo rk consistent with the ordering is not NP-hard. Indeed, if the in-degree of each nod e is bounded to k and all structures are assumed to have equal probability, th en this task can be accomplished in time O(nk) wherenis the number of nodes in the structure. Search over the ordering space has some useful properties. F irst, the order- ing space is signiﬁcantly smaller than the structure space: 2O(nlogn)orderings versus 2Ω(n2)structures where nis the number of nodes in the structure [Robin- son, 1973]. Second, each update in the ordering search makes a more global modiﬁcation to the current hypothesis and thus has more chan ce to avoid local minima. Third, since the acyclicity is already implied in th e ordering, there is no need to perform acyclicity checks, which is potentially a costly operation for large networks. The main disadvantage of ordering-based search is the need t o compute a large set of suﬃcient statistics ahead of time for each varia ble and each possible parent set. In the discrete case, these statistics are simpl y the frequency counts 25\nofinstantiations: #( xi,xπ(i))foreachxi∈Val(xi)andxπ(i)∈Val(xπ(i)). This cost would be very high if the number of samples in the dataset is large. How- ever, the cost can be reduced by using AD-tree data structure [Moore and Lee, 1998], or by pruning out possible parents for each node using SCHC [Friedman et al., 1999b], or by sampling a subset of the dataset randoml y. Here some algorithms that search through the ordering space are listed: •The ordering-based search was ﬁrst proposed in [Larranaga e t al., 1996] which uses a genetic algorithm search over the structures, a nd thus is very complex and not applicable in practice. •In [Friedman and Koller, 2003], the authors proposed to esti mate the probabilityofastructuralfeature(i.e.,anedge)overthe setofallorderings by using a Markov Chain Monte Carlo (MCMC) algorithm to sampl e over the possible orderings. The authors asserts that in the empi rical study, diﬀerent runs of MCMC over network structure typically lead to very diﬀerent estimates in the posterior probabilities over net work structure features, illustrating poor convergence to the stationary distribution. By contrast, diﬀerent runs of MCMC over orderings converge rel iably to the same estimates. •In [Teyssier and Koller, 2005], the authors proposed a simpl e greedy local hill-climbing with random restarts and a tabu list. First th e score of an ordering is deﬁned as the score of the best network consisten t with it. The algorithm starts with a random ordering of the variables . In each iteration, a swap operation is performed on any two adjacent variables in the ordering. Thus the branching factor for this swap oper ation is O(n). The search stops at a local maximum when the ordering with t he highest score is found. The tabu list is used to prevent the al gorithm from reversing a swap that was executed recently in the searc h. Given an ordering, the algorithm then tries to ﬁnd the best set of pare nts for each node using the Sparse Candidate algorithm followed by exhau stive search. •In [Koivisto, 2004, Singh and Moore, 2005], the authors prop osed to use Dynamic Programming to search for the optimal structure. Th e key in the dynamic programming approach is the ordering ≺, and the marginal posterior probability of the feature f p(f|≺) =∑ ≺p(≺|x)p(f|x,≺) Unlike [Friedman and Koller, 2003] which uses MCMC to approx imate the above value, the dynamic programming approach does exac t summa- tion using the permutation tree. Although this approach may ﬁnd the exactly best structure, the complexity is O(n2n+nk+1C(m)) wherenis the number of variables, kis a constant in-degree, and C(m) is the cost 26\nof computing a single local marginal conditional likelihoo d for m data in- stances. The authors acknowledge that the algorithm is feas ible only for n≤26. 27\nChapter 4 Regression-based Algorithms 4.1 Regression Model GivenNsample data points as ( xi,yi) and pre-deﬁned basis functions φ(·), the task of regression is to ﬁnd a set of weights wsuch that the basis functions give the best prediction of the label yifrom the input xi. The performance of the prediction is given by an loss function ED(w). For example, in a linear regression, ED(w) =1 2N∑ i=1( yi−w⊤φ(xi))2(4.1) To avoid over-ﬁtting, a regularizer is usually added to pena lize the weights w. So the regularized loss function is: E(w) =ED(w)+λEW(w) (4.2) The regularizer penalizes each element of w: EW(w) =M∑ j=1αi∝bardblwj∝bardblq When allαi’s are the same, then EW(w) =∝bardblwj∝bardblq where∝bardbl·∝bardblqis theLqnorm,λis the regularization coeﬃcient that controls the relative importance of the data-dependent error and the regularization term. With diﬀerent values of q, the regularization term may give diﬀerent results: 28\n1. Whenq= 2, the regularizer is in the form of sum-of-squares EW(w) =1 2w⊤w This particular choice of regularizer is known in machine le arning liter- ature as weight decay [Bishop, 2006] because in sequential learning al- gorithm, it encourages weight values to decay towards zeros , unless sup- ported by the data. In statistics, it provides an example of a parameter shrinkage method because it shrinks parameter values towar ds zero. One advantage of the L2regularizer is that it is rotationally invariant in the feature space. To be speciﬁc, given a deterministic lear ning algorithm L, it is rotationally invariant if, for any training set S, rotational matrix Mand test example x, there isL[S](x) =L[MS](Mx). More generally, if Lis a stochastic learning algorithm so that its predictions a re random, it is rotationally invariant if, for any S,Mandx, the prediction L[S](x) and L[MS](Mx) have the same distribution. A complete proof in the case of logistic regression is given in [Ng, 2004]. This quadratic ( L2) regularizer is convex, so if the loss function being optimized is also a convex function of the weights, then the r egularized loss has a single global optimum. Moreover, if the loss funct ionED(w) is in quadratic form, then the minimizer of the total error fu nction has a closed form solution. Speciﬁcally, if the data-dependent errorED(w) is the sum-of-squares error as in Equation 4.2, then setting the gradient with respect to wto zero, then the solution is w= (λI+Φ⊤Φ)−1Φ⊤t This regularizer is seen in ridge regression [Hoerl and Kennard, 2000], the support vector machine [Hoerl and Kennard, 2000, Schlkopf a nd Smola, 2002] and regularization networks [Girosi et al., 1995]. 2.q= 1 is called lassoregression in statistics [Tibshirani, 1996]. It has the property that if λis suﬃciently large, then some of the coeﬃcients wiare driven to zero, which leads to a sparse model in which the corr esponding basis functions play no role. To see this, note that the minim ization of Equation 4.2 is equivalent to minimizing the unregularized sum-of-squares error subject to the constraint over the parameters: argmin w1 2N∑ i=1( yi−w⊤φ(xi))2(4.3) s. t.M∑ j=1∝bardblwj∝bardblq≤η (4.4) 29\nFigure 4.1: Contours of the unregularized objective functi on (blue) along with the constraint region (yellow) with L2-regularizer (left) and L1-regularizer. The lasso regression gives a sparse solution. Figure excerpted from [Bishop, 2006]. TheLagrangianofEquation4.3givesEquation4.2. Thespars ityoftheso- lution can be seen from Figure 4.1. Theoretical study has als o shown that lassoL1regularization may eﬀectively avoid over-ﬁtting. In [Dudk et al., 2004], it is shown that the density estimation in log-linear models using L1-regularized likelihood has sample complexity that grows o nly logarith- mically in the number of features of the log-linear model; Ng [2004] and Wainwright et al. [2006] show a similar result for L1-regularized logistic regression respectively. The asymptotic properties of Lasso-type estimates in regre ssion have been studied in detail in [Knight and Fu, 2000] for a ﬁxed number of variables. Their results say that the regularization parameter λshould decay for an increasing number of observations at least as fast as N−1/2to obtain N1/2-consistent estimate where Nis the number of observations. 3. If 00≡0 is deﬁned, then the L0regularization contributes a ﬁxed penalty αifor each weight wi∝\\e}atio\\slash= 0. If all αiare identical, then this is equivalent to setting a limit on the maximum number of non-zero weights. How- ever, theL0norm is not a convex function, and this tends to make exact optimization of the objective function expensive. Ingeneral,the Lqnormhasparsimoniousproperty(withsomecomponents being exactly zero) for q≤1, while the optimization problem is only convex forq≥1. SoL1regularizer occupies a unique position, as q= 1 is the only value of qsuch that the optimization problem leads to a sparse solution, while the optimization problem is still convex. 30\n4.2 Structure Learning through Regression Learning a graphical structure by regression is gaining pop ularity in recent years. The algorithms proposed mainly diﬀer in the choice of the objective loss functions. They are listed in the following according to the diﬀerent objectives they use. 4.2.1 Likelihood Objective Methods in this category use the negative likelihood or log- likelihood of the data given the parameters of the model as the objective loss funct ionED(·). •In [in Lee et al., 2006], the authors proposed a L1-regularized structure learning algorithm for Markov Random Field, speciﬁcally, i n the frame- work of log-linear models. Given a variable set X={x1,···,xn}, a log- linear model is deﬁned in terms of a set of feature functions fk(xk), each of which is a function that deﬁnes a numerical value for each a ssignment xkto some subset xk⊂X. Given a set of feature functions F={fk}, the parameters of the log-linear model are weights θ={θk:fk∈F}. The overall distribution is deﬁned as: Pθ(x) =1 Z(θ)exp ∑ fk∈Fθkfk(x)  whereZ(θ) is a normalizer called partition function. Given an iid tra ining datasetD, the log-likelihood function is: L(M,D) =∑ fk∈Fθkfk(D−MlogZ(θ) =θ⊤f(D)−MlogZ(θ) wherefk(D) =∑textM m=1fk(xk[m]) is the sum of the feature values over the entiredataset, f(D)isthevectorwherealloftheseaggregatefeatureshave been arranged in the same order as the parameter vector, and θ⊤f(D) is a vector dot-product operation. To get a sparse MAP approxima tion of the parameters, a Laplacian parameter prior for each feature fkis introduced such that P(θk) =βk 2exp(−βk|θk|) And ﬁnally the objective function is: max θθ⊤f(D)−MlogZ(θ)−∑ kβk|θk| 31\nBefore solving this optimization problem to get the paramet ers, features should be included into the model. Instead of including all f eatures in advance, the authors use grafting procedure [Perkins et al., 2003] and gain-based method[Pietraetal.,1997]tointroducefeaturesintothem odel incrementally. •In [Wainwright et al., 2006], the authors restricted to the I sing model, a special family of MRF, deﬁned as p(x,θ) = exp ∑ s∈Vθsxs+∑ (s,t)∈Eθstxsxt−Ψ(θ)  Thelogisticregressionwith L1-regularizationthatminimizingthenegative log likelihood is achieved by optimizing: ˆθs,λ= argmin θ∈Rp(g 1 nn∑ i=1( log(1+exp( θ⊤z(i,s)))−x(i) sθ⊤z(i,s)) +λn∝bardblθ\\s∝bardbl1)g 4.2.2 Dependency Objective Algorithms in this category use linear regression to estima te the Markov blanket of each node in a graph. Each node is considered dependent on n odes with nonzero weights in the regression. •In [Meinshausen and B¨ uhlmann, 2006], the authors used line ar regression withL1regularizationtoestimatetheneighborsofeachnodeinaGa ussian graphical model: ˆθi,λ= argmin θ:θi=01 n∝bardblxi−θ⊤x∝bardbl2 2+λ∝bardblθ∝bardbl1 Theauthorsdiscussedindetailthechoiceofregularizerwe ightλ, forwhich thecross-validationchoiceisnotthebestundercertainci rcumstances. For the solution, the authors proposed an optimal choice of λunder certain assumptions with full proof. •In[Fan,2006], theauthorsproposedtolearnGGMfromdirect edgraphical models using modiﬁed Lasso regression, which seems a promis ing method. The algorithm is listed here in detail. GivenaGGMwithvariables x= [x1,···,xp]⊤andthemultivariate Gaus- sian distribution with covariance matrix Σ: P(x) =1 (2π)p/2|Σ|1/2exp(g −1 2x⊤Σ−1x)g This joint probability can always be decomposed into the pro duct of mul- tiple conditional probabilities: P(x) =p∏ i=1P(xi|xi+1,···,p) 32\nSince the joint probability in the GGM is a multivariate Gaus sian dis- tribution, each conditional probability also follows Gaus sian distribution. This implies that for any GGM there is at least one DAG with the same joint distribution. SupposethatforaDAGthereisaspeciﬁcorderingofvariable sas1,2,···,p. Each variable xionly has parents with indices larger than i. Letβde- note the regression coeﬃcients and Ddenote the data. The posterior probability given the DAG parameter βis P(D|β) =p∏ i=1P(xi|x(i+1):p,β) Suppose linear regression xi=∑textp j=i+1βjixj+ǫiwhere the error ǫifollows normal distribution ǫi∼N(0,ψi), then x= Γx+ǫ ǫ∼Np(0,Ψ) Where Γ is an upper triangular matrix, Γ ij=βji,i<j,ǫ= (ǫ1,···,ǫp)⊤ and Ψ =diag(ψ1,···,ψp). Thus x= (I−Γ)−1ǫ Soxfollows a joint multivariate Gaussian distribution with co variance matrix and precision matrix as: Σ = (I−Γ)−1Ψ((I−Γ)−1)⊤ Ω = (I−Γ)⊤Ψ−1(I−Γ) WishartpriorisassignedtotheprecisionmatrixΩsuchthat Ω∼Wp(δ,T) withδdegrees of freedom and diagonal scale matrix T=diag(θ1,···,θp). Eachθiis a positive hyper prior and satisﬁes P(θi) =λ 2exp(−λθi 2) Letβi= (β(i+1)i,···,βpi)⊤, andTirepresents the sub-matrix of Tcorre- spondingtovariables x(i+1):p. Thentheassociatedpriorfor βiisP(βi|ψi,θ(i+1):p) = Np−1(0,Tiψi) [Geiger and Heckerman, 2002], thus: P(βji|ψi,θj) =N(0,θjψi) And the associated prior for ψiis P(ψ−1 i|θi) = Γ(gδ+p−1 2,θ−1 i 2)g 33\nwhere Γ(·) is the Gamma distribution. Like in [Figueiredo and Jain, 20 01], the hyper prior θcan be integrated out from prior distribution of βjiand thus P(βji|ψi) =∫display∞ 0P(βji|ψi,θj)P(θj) =1 2(gλ ψi)g exp(g −(λ ψi)1 2|βji|)g Suppose there are Ksamples in the data Dandxkiis theith variable in thekth sample, then P(βi|ψi,D)∝P(xix(i+1):p,βi,ψi)P(βi|ψi) ∝exp(g∑text k(xki−∑textp j=i+1βjixkj)2+√λψi∑textp j=i+1|βji| −ψi)g and P(ψ−1 i|θi,βi,D) = Γ(g δ+p−i+K 2,θ−1 i+∑text k(xki−∑textp j=i+1βjixkj)2 2)g The MAP estimation of βiis: ˆβi= argmin∑ k xki−p∑ j=i+1βjixkj 2 +/radicalbig λψip∑ j=i+1|βji| ˆβiis the solution of a Lasso regression. The authors further proposed a Feature Vector Machine (FVM) which is an advance to the the generalized Lasso regression (GLR) [Ro th, 2004] which incorporates kernels, to learn the structure of undir ected graphical models. The optimization problem is: argmin β1 2∑ p,qβpβqK(fp,fq) s.t./vextendsingle/vextendsingle/vextendsingle/vextendsingle/vextendsingle∑ pβpK(fq,fp)−K(fq,y)/vextendsingle/vextendsingle/vextendsingle/vextendsingle/vextendsingle≤λ 2,∀q whereK(fi,fj) =φ(fi)⊤φ(fj) is the kernel function, φ(·) is the mapping, either linear or non-linear, from original space to a higher dimensional space;fkis thek-th feature vector, and yis the response vector from the training dataset. 34\n4.2.3 System-identiﬁcation Objective Algorithms in this category [Arkin et al., 1998, Gardner et a l., 2003, Glass and Kauﬀman, 1973, Gustafsson et al., 2003, McAdams and Arkin, 1 998] get ideas from network identiﬁcation by multiple regression (NIR), w hich is derived from a branch of engineering called system identiﬁcation [Ljung , 1999], in which a model of the connections and functional relations between e lements in a network is inferred from measurements of system dynamics. The whole system is mod- eled using a diﬀerential equation, then regression algorit hms are used to ﬁt this equation. This approach has been used to identify gene regul atory networks. Here the key idea of this type of approaches is illustrated by using the algorithm in [Gustafsson et al., 2003] as an example. Near a steady-state point (e.g., when gene expression does n ot change sub- stantially over time), the nonlinear system of the genes may be approximated to the ﬁrst order by a linear diﬀerential equation as: dxt i dt=n∑ j=1wijxt j+ǫi wherext iis the expression of gene iat timet. The network of the interaction can be inferred by minimizing the residual sum of squares wit h constraints on the coeﬃcients: argmin wij∑ t n∑ j=1wijxt j−dxt i dt 2 s.t.n∑ j=1|wij|≤µi Note that this is essentially a Lasso regression problem sin ce the constraints added to the Lagrangian is equivalent to L1regularizers. Finally the adjancency matrixAof the network is identiﬁed from the coeﬃcients by Aij=/braceleftBigg 0 ifwji= 0 1 otherwise One problem with this approach is when the number of samples i s less than the number of variables, the linear equation is undetermined. T o solve this prob- lem, D’haeseleer et al. [1999] use non-linear interpolatio n to generate more data points to make the equation determined; Yeung et al. [2002] u se singular value decomposition (SVD) to ﬁrst decompose the training data, an d then constrain the interaction matrix by exploring the sparseness of the in teractions. 4.2.4 Precision Matrix Objective In [Banerjee et al., 2006], the authors proposed a convex opt imization algorithm for ﬁtting sparse Gaussian Graphical Model from precision m atrix. Given a 35\nlarge-scale empirical dense covariance matrix Sof multivariate Gaussian data, theobjectiveistoﬁndasparseapproximationoftheprecisi onmatrix. Assuming Xis the estimate of the precision matrix (the inverse of the va riance matrix). The optimization of the penalized maximum likelihood (ML) i s: max X≻0logdet(X)−Tr(SX)−ρ∝bardblX∝bardbl1 The problem can be eﬃciently solved by Nesterovs method [Nes terov, 2005]. 4.2.5 MDL Objective Methods in this category encode the parameters into the Mini mum Description Length (MDL) criterion, and tries to minimize the MDL with re spect to the regularization or constraints. •In [Schmidt and Murphy, 2007], the authors proposed a struct ure learning approachwhichusesthe L1penalizedregressionwithMDLaslossfunction to ﬁnd the parents/neighbors for each node, and then apply th e score- based search. The ﬁrst step is the L1regularized variable selection to ﬁnd the parents/neighbors set of a node by solving the following equation: ˆθL1 j(U) = argmin θNLL(j,U,θ)+λ∝bardblθ∝bardbl1 (4.5) whereλis the regularization parameter for the L1norm of the parameter vector.NLL(j,U,θ) is the negative log-likelihood of node jwith parents π(j) and parameters θ: MDL(G) =d∑ j=1NLL(j,πj,ˆθmle j+|ˆθmle j| 2logn (4.6) NLL(j,π(j),θ) =−N∑ i=1logP(Xij|Xi,π(j),θ) (4.7) whereNis the number of samples in the dataset. TheL1regularization will generate a sparse solution with many pa rame- ters being zero. The set of variables with non-zero values ar e set as the parents of each node. This hybrid structure learning algori thm is further discussed in Section 5.1. In general, this regression method is the same as the likelih ood objected approaches, since the term of the description length of mode l in Equa- tion 4.7 is incorporated into the regularization term in Equ ation 4.5. •In[GuoandSchuurmans,2006], theauthorsproposedaninter estingstruc- ture learning algorithm for Bayesian Networks, which incor porates pa- rameter estimation, feature selection and variable orderi ng into one single 36\nconvex optimization problem, which is essentially a constr ained regression problem. The parameters of the Bayesian network and the feat ure selec- tor variables are encoded in the MDL objective function whic h is to be minimized. The topological properties of the Bayesian netw ork (antisym- metricity, transitivity and reﬂexivity) are encoded as con straints to the optimization problem. 37\nChapter 5 Hybrid Algorithms and Others 5.1 Hybrid Algorithms Some algorithms perform the structure learning in a hybrid m anner to utilize the advantages of constraint-based, score-based or regres sion-based algorithms. Here we list some of them. •Max-min Hill-climbing (MMHC): In [Tsamardinos et al., 2006], the au- thors proposed a Max-min Hill-climbing (MMHC) algorithm fo r structure learning of Bayesian networks. The MMHC algorithm shares th e simi- lar idea as the Sparse Candidate Hill Climbing (SCHC) algori thm. The MMHC algorithm works in two steps. In the ﬁrst step, the skele ton of the network is learned using a local discovery algorithm called Max-Min Par- ents and Children (MMPC) to identify the parents and childre n of each node through the conditional independency test, where the c onditional sets are grown in a greedy way. In this process, the Max-Min he uristic is used to select the variables that maximize the minimum ass ociation with the target variable relative to the candidate parents a nd children. In the second step, the greedy hill-climbing search is perfo rmed within the constraint of the skeleton learned in the ﬁrst step. Unli ke the SCHC algorithm, MMHC does not impose a maximum in-degree for each node. •In [Schmidt and Murphy, 2007], the authors proposed a struct ure learn- ing approach which uses the L1 penalized regression to ﬁnd th e par- ents/neighbors for each node, and then apply the score-base d search. The ﬁrst step is the L1variable selection to ﬁnd the parents/neighbors set of a node. The regression algorithm is discussed in Section 4.2 .5. Aftertheparentsetsofallnodeareidentiﬁed, askeletonof thestructureis created using the ‘OR’ strategy [Meinshausen and B¨ uhlmann , 2006]. This procedure is called L1MB ( L1-regularized Markov blanket). The L1MB is 38\nplugged into structure search (MMHC) or ordering search [Te yssier and Koller, 2005]. In the application to MMHC, L1MB replaces the Sparse Candidate procedure to identify potential parents. In the a pplication to ordering search in [Teyssier and Koller, 2005], given the or dering, L1MB replaces the SC and exhaustive search. 5.2 Other Algorithms Besidesthestructurelearningalgorithmsmentionedbefor e, therearesomeother approaches. They are listed here. 5.2.1 Clustering Approaches The simplest structure learning method is through clusteri ng. First the similar- ities of any two variables are estimated, then any two variab les with similarity higher than a threshold are connected by an edge [Lukashin et al., 2003]. Here the similarity may take diﬀerent measures, including corre lation [Eisen et al., 1998, Spellman et al., 1998, Iyer et al., 1999, Alizadeh et al ., 2000], Euclidean distance [Wen etal., 1998, Tamayo etal., 1999, Tavazoie eta l., 1999] and mutual information [Butte and Kohane, 2000]. Using hierarchical c lustering [Manning et al., 2008], the hierarchy structure may be presented at di ﬀerent scales. 5.2.2 Boolean Models Some algorithms employed the Boolean models for structure l earning in gene regulatory network reconstruction [Thomas, 1973, Akutsu e t al., 1999, Liang et al., 1998]. These approaches assume the boolean relation ship between regu- lators and regulated genes, and tried to identify appropria te logic relationship among gene based on the observed gene expression proﬁles. 5.2.3 Information Theoretic Based Approach In [Basso et al., 2005], the authors employ the information t heoretic approaches for reconstructing gene regulatory network. It ﬁrst identi fy pairs of correlated genes based on the measurement of mutual information. It the n eliminates indirect interaction among genes by applying the well-know n staple of data transimission theory, the “data processing inequality” (D PI). There are two things unclear about this approaches: 1) Since the results c ould be sensitive to the order of elimination, it is important to provide a just iﬁcation about the order of edges to be eliminated. 2) Most of the discussion wit hin the paper is limited to loops with three edges. It is important to know how to address the cycles with more than three genes. 39\n5.2.4 Matrix Factorization Based Approach Methods in this category use matrix factorization techniqu es to identify the interactions between variables. The matrix factorization algorithms used in- cludes singular value decomposition [Alter et al., 2000, D’ haeseleer et al., 1999, Raychaudhuri et al., 2000], max-margin matrix factorizati on [DeCoste, 2006, Rennie and Srebro, 2005, Srebro et al., 2005] and non-negati ve matrix factor- ization [Badea and Tilivea, 2005, Paatero and Tapper, 1994, Hoyer and Dayan, 2004, Lee and Seung, 2001, Shahnaz et al., 2006, Weinberger e t al., 2005], net- work component analysis (NCA) [Liao et al., 2003]. Readers a re referred to read a technical report [Jin and Zhou, 2006] for more details of th is method. 40\nBibliography Tatsuya Akutsu, Satoru Miyano, and Satoru Kuhara. Identiﬁc ation of genetic networks from a small number of gene expression patterns und er the boolean network model. In Paciﬁc Symposium on Biocomputing , pages 17–28, 1999. Ash A. Alizadeh, Michael B. Eisen, R. Eric Davis, Chi Ma, Izid ore S. Lossos, Andreas Rosenwald, Jennifer C. Boldrick, Hajeer Sabet, Tru c Tran, Xin Yu, John I. Powell, Liming Yang, Gerald E. Marti, Troy Moore, Jam es Hudson, Lisheng Lu, David B. Lewis, Robert Tibshirani, Gavin Sherlo ck, Wing C. Chan, Timothy C. Greiner, Dennis D. Weisenburger, James O. A rmitage, Roger Warnke, Ronald Levi, Wyndham Wilson, Michael R. Greve r, John C. Byrd, David Botstein, Patrick O. Brown, and Louis M. Staudt. Distinct types of diﬀuse large b-cell lymphoma identiﬁed by gene expr ession proﬁling. Nature, 403(6769):503–511, 2000. Tim Van Allen and Russell Greiner. Model selection criteria for learning belief nets: An empirical comparison. In ICML ’00: Proceedings of the Seven- teenth International Conference on Machine Learning , pages 1047–1054, San Francisco, CA, USA, 2000. Morgan Kaufmann Publishers Inc. I SBN 1-55860- 707-2. OrlyAlter, PatrickO.Brown, andDavidBotstein. Singularv aluedecomposition for genome-wide expression data processing and modeling. Proceedings of the National Academy of Sciences of the United States of America , 97(18):10101– 10106, 2000. URL http://www.pnas.org/content/97/18/10101.abstract . Adam Arkin, John Ross, and Harley H. McAdams. Stochastic ki- netic analysis of developmental pathway bifurcation in pha geλ-infected escherichia coli cells. Genetics , 149(4):1633–1648, 1998. URL http://www.genetics.org/cgi/content/abstract/149/4 1633. Liviu Badea and Doina Tilivea. Sparse factorizations of gen e expression data guided by binding data. In PSB, 2005. Onureena Banerjee, Laurent El Ghaoui, Alexandre d’Aspremo nt, and Georges Natsoulis. Convex optimization techniques for ﬁtting spar se gaussian graph- ical models. In ICML ’06: Proceedings of the 23rd international conference 41\non Machine learning , pages 89–96, New York, NY, USA, 2006. ACM. ISBN 1-59593-383-2. doi: http://doi.acm.org/10.1145/114384 4.1143856. Albert-Laszlo Barabasi and Reka Albert. Emergence of scal- ing in random networks. Science, 286:509, 1999. URL http://www.citebase.org/abstract?id=oai:arXiv.org:c ond-mat/9910332 . Katia Basso, Adam A. Margolin, Gustavo Stolovitzky, Ulf Kle in, Riccardo Dalla-Favera, and Andrea Califano. Reverse engineering of regulatory net- works in human b cells. Nature Genetics , 37(4):382–390, 2005. Ashish Bhan, David J. Galas, and Gregory T. Dewey. A duplication growth model of gene expression networks. Bioinformatics , 18(11):1486–1493, November 2002. URL http://bioinformatics.oxfordjournals.org/cgi/conten t/abstract/18/11/1486 . Christopher M. Bishop. Pattern Recognition and Machine Learning (Informa- tion Science and Statistics) . Springer-Verlag New York, Inc., Secaucus, NJ, USA, 2006. ISBN 0387310738. C. Boutilier, N. Friedman, M. Goldszmidt, and D. Koller. Con text-speciﬁc independence in Bayesian networks. In Proceedings of the Twelfth Conference on Uncertainty in Artiﬁcial Intelligence , pages 115–123, 1996. Wray Buntine. Theory reﬁnement on bayesian networks. In UAI, pages 52–60. Morgan Kaufmann, 1991. A. J. Butte and I. S. Kohane. Mutual information relevance ne t- works: functional genomic clustering using pairwise entro py measure- ments. In Paciﬁc Symposium of Biocomputing , pages 418–429, Children’s Hospital Informatics Program, Boston, MA 02115, USA., 2000 . URL http://view.ncbi.nlm.nih.gov/pubmed/10902190 . David M. Chickering, David Heckerman, and Christopher Meek . Large-sample learning of bayesian networks is np-hard. J. Mach. Learn. Res. , 5:1287–1330, 2004. ISSN 1533-7928. URL http://portal.acm.org/citation.cfm?id=1044703 . David Maxwell Chickering. Learning bayesian networks is np -complete. In Learning from Data: Artiﬁcial Intelligence and Statistics V, pages 121–130. Springer-Verlag, 1996. David Maxwell Chickering and Craig Boutilier. Learning equ ivalence classes of bayesian-network structures. In Journal of Machine Learning Research , pages 150–157. Morgan Kaufmann, 1996. C. I. Chow, Sexior Member, and C. N. Liu. Approximating discr ete probabil- ity distributions with dependence trees. IEEE Transactions on Information Theory, 14:462–467, 1968. 42\nGregory F. Cooper and Edward Herskovits. A bayesian method f or the in- duction of probabilistic networks from data. Machine Learning , 9(4):309– 347, October 1992. doi: http://dx.doi.org/10.1007/BF009 94110. URL http://dx.doi.org/10.1007/BF00994110 . Thomas M. Cover and Joy A. Thomas. Elements of Information The- ory. Wiley-Interscience, August 1991. ISBN 0471062596. URL http://www.amazon.ca/exec/obidos/redirect?tag=citeu like09-20&amp;path=ASIN/0471062596 . Djurdje Cvijovicacute and Jacek Klinowski. Taboo search: A n approach to the multiple minima problem. Science, 267(5198):664–666, Febru- ary 1995. doi: http://dx.doi.org/10.1126/science.267.5 198.664. URL http://dx.doi.org/10.1126/science.267.5198.664 . Dennis DeCoste. Collaborative prediction using ensembles of maxi- mum margin matrix factorizations. In ICML ’06: Proceedings of the 23rd international conference on Machine learning , pages 249– 256, New York, NY, USA, 2006. ACM. ISBN 1-59593-383-2. doi: http://doi.acm.org/10.1145/1143844.1143876. P. D’haeseleer, X. Wen, S. Fuhrman, and R. Somogyi. Linear mo deling of mrna expression levels during cns development and injury. In Paciﬁc Symposium on Biocomputing. Paciﬁc Symposium on Biocomputing , page 41, 1999. Miroslav Dudk, Steven J. Phillips, and Robert E. Schapire. P erformance guar- antees for regularized maximum entropy density estimation . InProceedings of the 17th Annual Conference on Computational Learning The ory, pages 472–486. Springer Verlag, 2004. M. B. Eisen, P. T. Spellman, P. O. Brown, and D. Botstein. Clus - ter analysis and display of genome-wide expression pattern s.Proc Natl Acad Sci , 95(25):14863–14868, December 1998. ISSN 0027- 8424. doi: http://dx.doi.org/10.1073/pnas.95.25.14863 . URL http://dx.doi.org/10.1073/pnas.95.25.14863 . Liming Fan. Structure learning with large sparse undirecte d graphs and its applications. Technical report, Carnegie Mellon Universi ty, 2006. Mario A. T. Figueiredo and Anil K. Jain. Bayesian learning of sparse classiﬁers. InIn 2001 Conference on Computer Vision and Pattern Recogniti on (CVPR 2001, pages 35–41. IEEE Press, 2001. N. Friedman and M. Goldszmidt. Learning bayesian networks w ith local struc- ture.Learning in Graphical Models , pages 421–460, 1998. Nir Friedman and Moises Goldszmidt. Learning in Graph- ical Models , chapter Learning Bayesian networks with lo- cal structure, pages 252–262. MIT Press, 1996. URL http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10 .1.1.30.573 . 43\nNir Friedman and Daphne Koller. Being bayesian about networ k struc- ture. a bayesian approach to structure discovery in bayesia n networks. Machine Learning , 50(1-2):95–125, January 2003. ISSN 0885-6125. URL http://www.ingentaconnect.com/content/klu/mach/2003 /00000050/F0020001/05096739 . Nir Friedman, Lise Getoor, Daphne Koller, and Avi Pfeﬀer. Le arning proba- bilistic relational models. In IJCAI, pages 1300–1309. Springer-Verlag, 1999a. Nir Friedman, Iftach Nachman, and Dana Pe’er. Learning baye sian network structure from massive datasets: The “sparse candidate” al gorithm. In UAI, pages 206–215, 1999b. URL http://citeseer.ist.psu.edu/218089.html . T. S. Gardner, D. di Bernardo, D. Lorenz, and J. J. Collins. In - ferring genetic networks and identifying compound mode of a ction via expression proﬁling. Science, 301(5629):102–105, July 2003. ISSN 1095-9203. doi: http://dx.doi.org/10.1126/science.108 1900. URL http://dx.doi.org/10.1126/science.1081900 . Dan Geiger and David Heckerman. Parameter priors for direct ed acyclic graphical models and the characterization of several proba bility dis- tributions. The Annals of Statistics , 30(5):1412–1440, 2002. URL http://www.jstor.org/stable/1558719 . Federico Girosi, Michael Jones, and Tomaso Poggio. Regular ization theory and neural networks architectures. Neural Computation , 7:219–269, 1995. L. Glass and SA Kauﬀman. The logical analysis of continuous, non-linear bio- chemical control networks. Journal of Theoretical Biology , 39(1):103, 1973. Yuhong Guo and Dale Schuurmans. Convex structure learning f or bayesian networks: polynomial feature selection and approximate or dering. In UAI, 2006. Mika Gustafsson, Michael Hornquist, and Anna Lombardi. Lar ge- scale reverse engineering by the lasso. In ICSB, 2003. URL http://www.citebase.org/abstract?id=oai:arXiv.org:q -bio/0403012 . Jing-Dong J. Han, Nicolas Bertin, Tong Hao, Debra S. Goldber g, Gabriel F. Berriz, Lan V. Zhang, Denis Dupuy, Albertha J. Walhout, Mich ael E. Cu- sick, Frederick P. Roth, and Marc Vidal. Evidence for dynami cally orga- nizedmodularityintheyeastprotein-proteininteraction network. Nature, 430 (6995):88–93, July 2004. doi: http://dx.doi.org/10.1038 /nature02555. URL http://dx.doi.org/10.1038/nature02555 . A. J. Hartemink, D. K. Giﬀord, T. S. Jaakkola, and R. A. Young. Using graph- ical models and genomic expression data to statistically va lidate models of genetic regulatory networks. Pac Symp Biocomput , pages 422–433, 2001. URLhttp://view.ncbi.nlm.nih.gov/pubmed/11262961 . 44\nD. Heckerman, D. Geiger, and D. M. Chickering. Learning baye sian networks: The combination of knowledge and statistical dat a.Ma- chine Learning , 20(3):197–243, September 1995. ISSN 0885-6125. URL http://www.ingentaconnect.com/content/klu/mach/1995 /00000020/00000003/00422402 . David Heckerman, David M. Chickering, Christopher Meek, Ro bert Rounthwaite, and Carl Kadie. Dependency networks for in- ference, collaborative ﬁltering, and data visualization. Jour- nal of Machine Learning Research , 1:49–75, October 2000. URL http://www.jmlr.org/papers/volume1/heckerman00a/hec kerman00a.pdf . A. E. Hoerl and R. W. Kennard. Ridge regression: Biased estim ation for nonorthogonal problems. Technometrics , 42(1):80–86, 2000. Katsuhisa Horimoto and Hiroyuki Toh. Statistical estimati on of cluster bound- aries in gene expression proﬁle data. Bioinformatics , 17(12):1143–1151, December 2001. doi: http://dx.doi.org/10.1093/bioinfor matics/17.12.1143. URLhttp://dx.doi.org/10.1093/bioinformatics/17.12.1143 . Patrik O. Hoyer and Peter Dayan. Non-negative matrix factor ization with sparseness constraints. Journal of Machine Learning Research , 5:1457–1469, 2004. Su in Lee, Varun Ganapathi, and Daphne Koller. Eﬃcient struc ture learning of markov networks using ℓ1-regularization. In NIPS, 2006. V. R. Iyer, M. B. Eisen, D. T. Ross, G. Schuler, T. Moore, J. C. L ee, J. M. Trent, L. M. Staudt, J. Hudson, M. S. Boguski, D. Lashkari, D. Shalon, D. Botstein, and P. O. Brown. The transcriptional program in the response of human ﬁbroblasts to serum. Science, 283(5398):83–87, January 1999. ISSN 0036-8075. URL http://view.ncbi.nlm.nih.gov/pubmed/99102697 . Manfred Jaeger. Relational bayesian networks. In UAI, pages 266–273. Morgan Kaufmann, 1997. Manfred Jaeger. Complex probabilistic modeling with recur sive re- lational bayesian networks. Annals of Mathematics and Artiﬁ- cial Intelligence , 32(1-4):179–220, 2001. ISSN 1012-2443. URL http://portal.acm.org/citation.cfm?id=590425.590441 . H. Jeong, B. Tombor, R. Albert, Z. N. Oltvai, and A. L. Barab´ a si. The large- scale organization of metabolic networks. Nature, 407(6804):651–654, Octo- ber 2000. ISSN 0028-0836. doi: http://dx.doi.org/10.1038 /35036627. URL http://dx.doi.org/10.1038/35036627 . Rong Jin and Yang Zhou. Gene regulatory network reconstruct ion by matrix factorization. Technical Report MSU-CSE-06-33, Departme nt of Computer Science and Engineering, Michigan State University, 2006. 45\nSchafer Juliane and Strimmer Korbinian. An empirical bayes approach to inferring large-scale gene association networ ks. Bioinformatics , 21(6):754–764, March 2005. ISSN 1367-4803. doi: http://dx.doi.org/10.1093/bioinformatics/bti062 . URL http://dx.doi.org/10.1093/bioinformatics/bti062 . Robert E. Kass and Adrian E. Raftery. Bayes factors. Jour- nal of the American Statistical Association , 90(430):773– 795, 1995. doi: http://dx.doi.org/10.2307/2291091. URL http://dx.doi.org/10.2307/2291091 . H. Kitano. Computational system biology. Nature, 420:206–210, 2002. Keith Knight and Wenjiang Fu. Asymptotics for lasso-type es ti- mators. The Annals of Statistics , 28(5):1356–1378, 2000. URL http://www.jstor.org/stable/2674097 . Mikko Koivisto. Exact bayesian structure discovery in baye sian networks. J. of Machine Learning Research , 5:2004, 2004. Wai Lam and Fahiem Bacchus. Learning bayesian belief networ ks: An approach based on the mdl principle. Computational Intelligence , 10:269–293, 1994. P. Larranaga, M. Poza, Y. Yurramendi, R. H. Murga, and C. M. H. Kuijpers. Structure learning of bayesian networks by genet ic al- gorithms: a performance analysis of control parameters. Pat- tern Analysis and Machine Intelligence, IEEE Transactions on, 18 (9):912–926, 1996. doi: http://dx.doi.org/10.1109/34.5 37345. URL http://dx.doi.org/10.1109/34.537345 . Daniel D. Lee and H. Sebastian Seung. Algorithms for non-neg ative matrix factorization. In NIPS, pages 556–562. MIT Press, 2001. Shoudan Liang, Stefanie Fuhrman, and Roland Somogyi. Revea l: A general reverse engineering algorithm for inference of genetic net work architectures. InPSB, 1998. James C. Liao, Riccardo Boscolo, Young-Lyeol Yang, Linh M. T ran, Chiara Sabatti, and Vwani P. Roychowdhury. Network component anal ysis: Recon- struction of regulatory signals in biological systems. Proceedings of the Na- tional Academy of Sciences of the United States of America , 100(26):15522– 15527, 2003. URL http://www.jstor.org/stable/3149038 . L. Ljung. System identication: Theory for the user . Prentice-Hall, 1999. A. V. Lukashin, M. E. Lukashev, and R. Fuchs. Topology of gene expression networks as revealed by data mining and mode l- ing.Bioinformatics , 19(15):1909–1916, October 2003. ISSN 1367- 4803. doi: http://dx.doi.org/10.1093/bioinformatics/b tg333. URL http://dx.doi.org/10.1093/bioinformatics/btg333 . 46\nChristopher D. Manning, Prabhakar Raghavan, and Hin- rich Sch¨ utze. Introduction to Information Retrieval . Cam- bridge University Press, July 2008. ISBN 0521865719. URL http://www.amazon.ca/exec/obidos/redirect?tag=citeu like09-20&amp;path=ASIN/0521865719 . D. Margaritis. Learning bayesian networks model structure from data . PhD thesis, CMU, 2003. Dimitris Margaritis and Sebastian Thrun. Bayesian network induction via local neighborhoods. In Advances in Neural Information Processing Systems 12 , pages 505–511. MIT Press, 1999. H. H. McAdams and A. Arkin. Simulation of prokaryotic geneti c cir- cuits.Annu Rev Biophys Biomol Struct , 27:199–224, 1998. ISSN 1056- 8700. doi: http://dx.doi.org/10.1146/annurev.biophys. 27.1.199. URL http://dx.doi.org/10.1146/annurev.biophys.27.1.199 . Nicolai Meinshausen and Peter B¨ uhlmann. High-dimensiona l graphs and variable selection with the lasso. Ann. Statist. , 34(3):1436– 1462, 2006. doi: http://dx.doi.org/10.1214/00905360600 0000281. URL http://dx.doi.org/10.1214/009053606000000281 . Andrew Moore and Weng keen Wong. Optimal reinsertion: A new s earch oper- ator for accelerated and more accurate bayesian network str ucture learning. InIn Proceedings of the 20th International Conference on Mach ine Learning (ICML 03 , pages 552–559. AAAI Press, 2003. Andrew W. Moore and Mary S. Lee. Cached suﬃcient statistics f or eﬃcient ma- chine learning with large datasets. Journal of Artiﬁcial Intelligence Research , 8:67–91, 1998. URL http://citeseer.ist.psu.edu/moore97cached.html . Radford M. Neal. Connectionist learning of belief networks .Artif. Intell. , 56(1):71–113, 1992. ISSN 0004-3702. doi: http://dx.doi.o rg/10.1016/0004- 3702(92)90065-6. Yu Nesterov. Smooth minimization of non-smooth functions. Math. Program. , 103(1):127–152, 2005. ISSN 0025-5610. doi: http://dx.doi.org/10.1007/s10107-004-0552-5. Andrew Y. Ng. Feature selection, l1 vs. l2 regularization, a nd rotational invari- ance. In ICML ’04: Proceedings of the twenty-ﬁrst international con ference on Machine learning , page 78, New York, NY, USA, 2004. ACM. ISBN 1- 58113-828-5. doi: http://doi.acm.org/10.1145/1015330. 1015435. Pentti Paatero and Unto Tapper. Positive matrix factoriza- tion: A non-negative factor model with optimal utilization of error estimates of data values. Environmetrics , 5(2):111–126, 1994. doi: http://dx.doi.org/10.1002/env.3170050203. U RL http://dx.doi.org/10.1002/env.3170050203 . 47\nJudea Pearl. Probabilistic Reasoning in Intelligent Systems : Networks of Plau- sible Inference . Morgan Kaufmann, September 1988. ISBN 1558604790. URL http://www.amazon.ca/exec/obidos/redirect?tag=citeu like09-20&amp;path=ASIN/1558604790 . Simon Perkins, Kevin Lacker, and James Theiler. Grafting: f ast, incremental feature selection by gradient descent in function space. J. Mach. Learn. Res. , 3:1333–1356, 2003. ISSN 1533-7928. Stephen Della Pietra, Vincent Della Pietra, and John Laﬀert y. Inducing fea- tures of random ﬁelds. IEEE Transactions on Pattern Analysis and Machine Intelligence , 19:380–393, 1997. David Pollard. Convergence of stochastic process . Springer-Verlag, 1984. E. Ravasz, A. L. Somera, D. A. Mongru, Z. N. Oltvai, and A. L. Ba rabasi. Hier- archicalorganizationofmodularityinmetabolicnetworks .Science,297(5586): 1551–1555, August 2002. doi: http://dx.doi.org/10.1126 science.1073374. URLhttp://dx.doi.org/10.1126/science.1073374 . S. Raychaudhuri, J. M. Stuart, and R. B. Altman. Principal co mponents analysis to summarize microarray experiments: applicatio n to sporula- tion time series. Paciﬁc Symposium on Biocomputing. Paciﬁc Sympo- sium on Biocomputing , pages 455–466, 2000. ISSN 1793-5091. URL http://view.ncbi.nlm.nih.gov/pubmed/10902193 . Jasson D. M. Rennie and Nathan Srebro. Fast maximum margin ma - trix factorization for collaborative prediction. In ICML ’05: Proceed- ings of the 22nd international conference on Machine learni ng, pages 713– 719, New York, NY, USA, 2005. ACM. ISBN 1-59593-180-5. doi: http://doi.acm.org/10.1145/1102351.1102441. Jorma Rissanen. Stochastic Complexity in Statistical Inquiry Theory . World ScientiﬁcPublishingCo., Inc., RiverEdge, NJ,USA,1989. I SBN981020311X. R. W. Robinson. Counting labeled acyclic digraphs. In F. Har ary, editor, New Directions in Graph Theory . New York: Academic Press, 1973. V. Roth. The generalized lasso. IEEE Transactions on Neural Networks , 15: 16–28, 2004. S. Russel and P. Norvig. Articial ingelligence . Prentice-Hall., 1995. Mehran Sahami. Learning limited dependence bayesian class iﬁers. In In KDD- 96: Proceedings of the Second International Conference on K nowledge Dis- covery and Data Mining , pages 335–338. AAAI Press, 1996. M. Niculescu-Mizil Schmidt and K. A. Murphy. Learning graph ical model struc- ture using l1-regularization paths. In AAAI, 2007. Gideon Schwarz. Estimating the dimension of a model. The Annals of Statistics , 6(2):461–464, 1978. URL http://www.jstor.org/stable/2958889 . 48\nBernhard Schlkopf and Alex Smola. Learning with Kernels . MIT Press, 2002. E. Segal, M. Shapira, A. Regev, D. Pe’er, D. Botstein, D. Koll er, and N. Fried- man. Module networks: identifying regulatory modules and t heir condition- speciﬁc regulators from gene expression data. Nat Genet , 34(2):166–176, June 2003. ISSN 1061-4036. doi: http://dx.doi.org/10.103 8/ng1165. URL http://dx.doi.org/10.1038/ng1165 . Eran Segal. Rich probabilistic models for genomic data . PhD thesis, Stanford University, 2004. Farial Shahnaz, Michael W. Berry, V. Paul Pauca, and Robert J . Plem- mons. Document clustering using nonnegative matrix factor ization. Inf. Process. Manage. , 42(2):373–386, 2006. ISSN 0306-4573. doi: http://dx.doi.org/10.1016/j.ipm.2004.11.005. Ajit Singh and Andrew Moore. Finding optimal bayesian netwo rks by dynamic programming. Technical Report CMU-CALD-05-106, Carnegie Mellon Uni- versity, 2005. P. T. Spellman, G. Sherlock, M. Q. Zhang, V. R. Iyer, K. Anders , M. B. Eisen, P.O.Brown, D.Botstein, andB.Futcher. Comprehensiveiden tiﬁcationofcell cycle-regulated genes of the yeast saccharomyces cerevisi ae by microarray hy- bridization. Mol Biol Cell , 9(12):3273–3297, December 1998. ISSN 1059-1524. URLhttp://www.molbiolcell.org/cgi/content/abstract/9/1 2/3273. P. Spirtes, C. Glymour, and R. Scheines. Causation, prediction, and search . MIT press, 2000. Nathan Srebro. Maximum likelihood bounded tree-width mark ov networks. In Artiﬁcial Intelligence , pages 504–511, 2001. Nathan Srebro, Jason D. M. Rennie, and Tommi S. Jaakkola. Max imum-margin matrix factorization. In Advances in Neural Information Processing Systems 17, pages 1329–1336. MIT Press, 2005. Pablo Tamayo, Donna Slonim, Jill Mesirov, Qing Zhu, Sutisak Kitareewan, Ethan Dmitrovsky, Eric S Lander, and Todd R Golub. Interpret ing patterns of gene expression with self-organizing maps: Methods and a pplication to hematopoietic diﬀerentiation. PNAS, 96(6):2907–2912, 1999. S. Tavazoie, J. D. Hughes, M. J. Campbell, R. J. Cho, and G. M. C hurch. Systematic determination of genetic network architecture .Nat Genet , 22(3): 281–285, July 1999. ISSN 1061-4036. doi: http://dx.doi.or g/10.1038/10343. URLhttp://dx.doi.org/10.1038/10343 . Marc Teyssier and Daphne Koller. Ordering-based search: A s imple and eﬀective algorithm for learning bayesian networks. In Proceedings of the Conference on Uncertainty in Artiﬁcial Intelligence , 2005. URL http://robotics.stanford.edu/~koller/Papers/Teyssie r+Koller:UAI05.pdf . 49\nRene Thomas. Boolean formalization of genetic control cir- cuits. Journal of Theoretical Biology , 42(3):563–585, December 1973. doi: http://dx.doi.org/10.1016/0022-5193(73)902 47-6. URL http://dx.doi.org/10.1016/0022-5193(73)90247-6 . Robert Tibshirani. Regression shrinkage and selection via the lasso. Journal of the Royal Statistical Society, Series B , 58:267–288, 1996. Ivan Titov and James Henderson. Incremental bayesian netwo rks for structure prediction. In ICML ’07: Proceedings of the 24th international conference on Machine learning , pages 887–894, New York, NY, USA, 2007. ACM. ISBN 978-1-59593-793-3. doi: http://doi.acm.org/10.1145/12 73496.1273608. Hiroyuki Toh and Katsuhisa Horimoto. Inference of a genetic network by a com- bined approach of cluster analysis and graphical gaussian m odeling. Bioin- formatics , 18(2):287–297, 2002. IoannisTsamardinos, LauraE.Brown, andConstantinF.Alif eris. Themax-min hill-climbing bayesian network structure learning algori thm.Mach. Learn. , 65(1):31–78, 2006. ISSN 0885-6125. doi: http://dx.doi.or g/10.1007/s10994- 006-6889-7. Martin J. Wainwright, Pradeep Ravikumar, and John D. Laﬀert y. High- dimensional graphical model selection using l1-regularized logistic regression. InNIPS, pages 1465–1472. MIT Press, 2006. ISBN 0-262-19568-2. URL http://dblp.uni-trier.de/rec/bibtex/conf/nips/Wainw rightRL06 . D. J. Watts and S. H. Strogatz. Collective dynamics of small- world networks. Nature, 393(6684):440–442, June 1998. ISSN 0028-0836. doi: http://dx.doi.org/10.1038/30918. URL http://dx.doi.org/10.1038/30918 . Kilian Q. Weinberger, Benjamin D. Packer, and Lawrence K. Sa ul. Nonlin- ear dimensionality reduction by semideﬁnite programming a nd kernel matrix factorization. In In Proceedings of the Tenth International Workshop on Ar- tiﬁcial Intelligence and Statistics , pages 381–388, 2005. Xiling Wen, Stefanie Fuhrman, George S. Michaels, Daniel B. Carr, Susan Smith, Jeﬀery L. Barker, and Roland Somogyi. Large-sc ale temporal gene expression mapping of central nervous system develop- ment. Proceedings of the National Academy of Sciences , 95(1):334– 339, January 1998. doi: http://dx.doi.org/10.1073/pnas. 95.1.334. URL http://dx.doi.org/10.1073/pnas.95.1.334 . A. Wille, P. Zimmermann, E. Vranov´ a, A. F¨ urholz, O. Laule, S. Bleuler, L. Hennig, A. Prelic, P. von Rohr, L. Thiele, E. Zitzler, W. Gr uis- sem, and P. B¨ uhlmann. Sparse graphical gaussian modeling o f the iso- prenoid gene network in arabidopsis thaliana. Genome Biol , 5(11), 2004. ISSN 1465-6914. doi: http://dx.doi.org/10.1186/gb-2004 -5-11-r92. URL http://dx.doi.org/10.1186/gb-2004-5-11-r92 . 50\nY. Xiang, S. K. M. Wong, and N. Cercone. A “microscopic” study of minimum entropy search in learning decomposable markov n et- works. Mach. Learn. , 26(1):65–92, 1997. ISSN 0885-6125. doi: http://dx.doi.org/10.1023/A:1007324100110. M. K. Yeung, J. Tegn´ er, and J. J. Collins. Reverse engineeri ng gene networks using singular value decomposition and robus t regres- sion. Proc Natl Acad Sci U S A , 99(9):6163–6168, April 2002. ISSN 0027-8424. doi: http://dx.doi.org/10.1073/pnas.09 2576199. URL http://dx.doi.org/10.1073/pnas.092576199 . 51\n",
  "metadata": {
    "paper_id": "1111.6925v1",
    "downloaded_at": "2025-08-24T22:59:02.971875+00:00"
  },
  "processed_at": "2025-08-24T22:59:02.971891+00:00"
}