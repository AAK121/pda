{
  "content": "IEEE TRANSACTIONS ON VEHICULAR TECHNOLOGY , VOL. XX, NO. XX, XXX 2020 1 Analysis on Computation-Intensive Status Update in Mobile Edge Computing Qiaobin Kuang, Jie Gong, Member, IEEE , Xiang Chen, Member, IEEE , and Xiao Ma, Member, IEEE Abstract —In status update scenarios, the freshness of infor- mation is measured in terms of age-of-information (AoI), which essentially reﬂects the timeliness for real-time applications to transmit status update messages to a remote controller. For some applications, computational expensive and time consuming data processing is inevitable for status information of messages to be displayed. Mobile edge servers are equipped with adequate computation resources and they are placed close to users. Thus, mobile edge computing (MEC) can be a promising technology to reduce AoI for computation-intensive messages. In this paper, we study the AoI for computation-intensive messages with MEC, and consider three computing schemes: local computing, remote computing at the MEC server, and partial computing, i.e., some part of computing tasks are performed locally, and the rest is executed at the MEC server. Zero-wait policy is adopted in all three schemes. Speciﬁcally, in local computing, a new message is generated immediately after the previous one is revealed by computing. While in remote computing and partial computing, a new message is generated once the previous one is received by the remote MEC server. With inﬁnite queue size and exponentially distributed transmission time, closed-form average AoI for exponentially distributed computing time is derived for the three computing schemes. For deterministic computing time, the average AoI is analyzed numerically. Simulation results show that by carefully partitioning the computing tasks, the average AoI in partial computing is the smallest compared to local computing and remote computing. The results also indicate numerically the conditions on which remote computing attains smaller average AoI compared with local computing. Index Terms —Age-of-information, mobile edge computing, computation-intensive. I. I NTRODUCTION In recent years, various kinds of real-time applications such as ads bidding, stocks forecast, weather monitoring, and social networks have become a focus of attention. These applications have high requirement in the freshness of status information for making accurate decision. The freshness of data can be measured by age-of-information (AoI) [2, 3]. It is deﬁned as the time elapsed since the latest delivery of the update was generated. AoI has attracted many researchers in academic. AoI was ﬁrstly proposed in [2, 3] as a metric of the information freshness at the target node. In [3], the authors obtained a general result for extensive service systems with the update messages served with ﬁrst-come-ﬁrst-served (FCFS) principle, Part of this paper was presented at the 11th International Conference on Wireless Communications and Signal Processing, Xi’an, China, Oct. 2019 [1]. Q. Kuang and X. Chen are with the School of Electronics and Information Technology, Sun Yat-sen University, Guangzhou 510006, China. J. Gong and X. Ma are with the School of Data and Computer Science, Sun Yat-sen University, Guangzhou 510006, China. J. Gong is the corresponding author (email: gongj26@mail.sysu.edu.cn).and speciﬁcally considered MM1,MD1and DM1 standard queuing models. In [4], status updating from multiple sources was analyzed. In [5] and [6], minimizing AoI for multi-hop wireless networks with interference-free networks and general interference constrains were considered, respec- tively. The above references focus on the update messages stochastically generated at the source. Thus, the message has to wait in the queue when the server is busy. Thus AoI may increase due to the queuing delay. A just-in-time policy was proposed in [7] to solve the problem according to the knowl- edge of the system state, for example, to generate messages only when the server is idle. The policy is also called zero-wait policy [8] or the work-conserving policy [9]. The authors in [8] also noticed that there can be better polices other than the zero- wait policy in many scenarios. In [10], peak age was taken as a new measurement of the freshness of information because of its analytically convenience. Recently, some researchers are devoted to developing new tools for AoI analysis in networks. In particular, ref. [11] explicitly calculated the average age over a multi-hop network of preemptive servers by using a stochastic hybrid system (SHS). And in [12], the authors applied SHS in the analysis of the temporal convergence of higher order AoI moments, and enable the moment generation function to characterize the stationary distribution of an AoI process in multi-hop networks. The above papers only pay attention to the inﬂuence of data transmission and queuing on AoI. However, the impact of data processing on AoI is non-negligible in some real- time applications. Take autonomous driving as an example, when a status update is an image, it needs not only to be transmitted to the controller, but also to be processed to expose the embedded status information. Unfortunately, subject to the limited computational capacity of the local processor, data processing could be computational expensive and time consuming. Mobile edge computing (MEC) can be a potential technique to solve the above problem for reducing the AoI of computation-intensive messages, since it has the ability to provide abundant cloud-like computing resource via integrated MEC servers deployed at the network edge such as access points and cellular base stations, as well as to cut down the response time in comparison with the centralized cloud [13, 14]. Motivated by this, we consider introducing MEC to process the computation-intensive message. In MEC systems, the computing tasks can be ofﬂoaded to an MEC server. As the MEC server usually has sufﬁcient computing capacity and is close to mobile users, ofﬂoading can greatly save the user’s energy and reduce the computing time. For computation ofﬂoading, it is crucial to determine whetherarXiv:2002.06400v1 [cs.IT] 15 Feb 2020\nIEEE TRANSACTIONS ON VEHICULAR TECHNOLOGY , VOL. XX, NO. XX, XXX 2020 2 or not to ofﬂoad and what and how much should be ofﬂoaded [15]. The computation ofﬂoading decision is inﬂuenced by a number of parameters such as the QoS requirements to be met (e.g., in AoI minimization, energy efﬁciency maximization), as well as the capacities of processing nodes and the availability of radio resources for wireless packet transmission. And there are mainly two widely used computation task models, namely binary computation ofﬂoading as well as partial computation ofﬂoading [13, 14]. For binary ofﬂoading, the task is insepa- rable because its tight integration or relatively simplicity, such as speech recognition and natural language translation. Thus, the whole computation task is performed either locally by the mobile user or ofﬂoaded to the MEC server. For partial ofﬂoading, the computation task can be divided into more than one part. Some parts are computed by mobile user locally and the rest are transmitted to and computed at the MEC server. Applications of partial ofﬂoading consist of multiple ﬁne-grained processes/components, such as augmented reality and face detection. If the composable components of the task are independent, the computing process can be executed both locally and remotely in parallel. In the literature, many works investigated computation ofﬂoading in MEC systems. Minimizing the execution delay is studied in [16–19]. Under the constraint of execution delay, [20–23] minimized the en- ergy consumption and [24] maximized the system scalability. A balance between execution delay and energy consumption for computation ofﬂoading was considered in [25–27]. While in practical applications, completely parallel execution for the task-input bits may be unpractical, since the bit-wise correlation hinders arbitrarily division into different groups. In this paper, we consider the computation task generated at the information source to be computed in three ways: 1) local computing, where the task is computed as a whole at the local processor; 2) remote computing, where the task is computed as a whole at the MEC server; 3) partial computing, where the task is ﬁrstly computed at the local processor and then the output of the local processor is transferred to the MEC server for further computation. Note that in the third method, the size of the output obtained by means of local processing is less than the size of the message generated at the source node. In terms of computation-intensive messages, apart from the two affects mentioned above, the message generation frequency and the delay caused by data transmission and queuing, data processing delay is also non-negligible for the research of AoI. For example, ref. [28] considered AoI minimization in two data processing scenes, the complicated initial feature extraction and classiﬁcation in computer vision, as well as the optimization of sampling and updating processes in an Internet of things device’s sampled physical process. The authors in [29] considered a general analysis with packet management for average AoI and average peak AoI with a computation server and a transmission queue. Ref. [30] put forward new scheduling schemes for computing and network phases in vehicular networks by combining the computation and information freshness. In [31], the authors investigated bidirectional timely data exchanging between a fog node and a mobile user in a fog computing system. For a resourceconstrained edge cloud system, the authors in [32] considered a greedy trafﬁc scheduling policy to minimize the overall age penalty of multiple users. In [33], a cloud computing status updating was studied with preemption policy. The authors in [34] proposed a new performance metric called age of task (AoT) to evaluate the temporal value of computation tasks and jointly considered task scheduling, computation ofﬂoading and energy consumption. Although the above papers consid- ered data processing, they did not take advantage of MEC’s short distance to the source node and sufﬁcient computation resources. In this paper, we concentrate on the average AoI for computation-intensive messages in an MEC system. We study the AoI performance with three computing strategies, includ- ing local computing, remote computing and partial computing. It has not been studied to the best of our knowledge. Zero-wait policy is applied to the three computing schemes. Speciﬁcally, local computing generates the update message immediately after the computation of the last update message. For remote and partial computing, the generation of a new update message comes after the previous one’s arrival at the MEC server. In the three computing schemes, the computing follows FCFS principle. Assume the transmission time follows an exponen- tial distribution, and consider exponentially distributed and deterministic computing time with inﬁnite computing queue size. The main contributions of this article are summarized as follows: \u000fWe derive the closed-form average AoI for the three computing schemes with exponentially distributed com- puting time. We found that by carefully partitioning the computing task, partial computing performs the best compared with local computing and remote computing. And it is signiﬁcantly better than remote computing when the ratio of transmission rate and remote computing rate is very small or very large. If the transmission rate is small, the performance of local computing is the same as partial computing. \u000fThe average AoI with deterministic computing time is obtained numerically. Simulation results show that, with large local computing rate and with both small trans- mission rate and large one, local computing and partial computing have similar performance. While, with small local computing rate, remote computing outperforms lo- cal computing. \u000fThe inﬂuence of message size, required number of central processing unit (CPU) cycles, data rate, as well as com- puting capacity of the MEC server for data processing on the average AoI is studied by numerical simulations. It is found that remote computing does not always outperform local computing in terms of average AoI. We characterize numerically when remote computing should be adopted compared with local computing. The rest of the paper is organized as follows. In the next section, the system model and the average AoI about the three computing schemes are presented. The analytic results for average AoI with exponentially distributed computing time and deterministic computing time are discussed in Section III\nIEEE TRANSACTIONS ON VEHICULAR TECHNOLOGY , VOL. XX, NO. XX, XXX 2020 3 Tx Local Server Source Rx Destination Acknowledgement Transmission Queue Computing Queue (a) Local computing Tx MEC Server Rx Acknowledgement Transmission Queue Computing Queue Source Destination (b) Remote computing Tx MEC Server Rx Acknowledgement Transmission Queue Computing Queue Destination Local Server Source Computing Queue (c) Partial computing Fig. 1. System models and Section IV , respectively. And numerical analysis for ex- ponentially distributed computing time are showed in Section V . This paper is concluded in Section VI. II. S YSTEM MODEL AND AVERAGE AOI Fig. 1 presents a status monitoring and control system for computation-intensive messages. Firstly, the source generates system status. Then, one of the local server and the remote server or both of them, will process system status. In the next, the target node receives the transmitted processed signal. During the procedure, it is vital to maintain the freshest processed status for the accuracy of control. Details of the three schemes of local computing, remote computing and partial computing will be described in the following parts. A. Local computing, remote computing and partial computing model Since both the MEC server and the user have the computing ability, we compare three computing methods in this paper. 1) Local Computing: Depicted in Fig. 1(a), this scheme allocates all computation-intensive data to local computation before sending the processed information to the target. In particular, the source ﬁrstly generates a status update message and then arrives at the computing queue. After the computation is completed by the local server, the computing result arrives at the transmission queue and then is transmitted to the destination node through the channel. 2) Remote Computing: In this scheme, the computation- intensive message is transmitted to the MEC server and then computed remotely, as illustrated in Fig. 1(b). Particularly, the status update message generated by the source node is transmitted through the channel and arrives at the computing queue in the MEC server. Finally, the MEC server completes the computation of the status update message based on FCFS principle and sends the result to the destination node.3) Partial Computing: As shown in Fig. 1(c), the last scheme partially computes the computation-intensive data by the local server, and then sends intermediate computing result to the MEC server for further computing. Speciﬁcally, the local server partially processes the computation-intensive data, and the intermediate computing result enters the transmission queue. Then, the intermediate result is transmitted to the remote computing queue to wait for the MEC server to ﬁnish the rest computing part which is also based on the FCFS principle. When the computation is completely ﬁnished, the result can be sent to the destination node. B. Zero-Wait Message Generation Policy In this section, we present the three computing schemes with zero-wait message generation policy [8], a policy that new message is generated immediately after the last one completes its computing or transmission. Intuitively, the zero- wait policy attains good performance as the waiting in a queue is avoided. Other message generation policies will be considered in the future work. The detailed zero-wait policies in the three schemes are given as follows. 1) Local Computing: In local computing, a new status update message waits to be generated until the previous message is totally computed by the local server. Therefore, the computing queue is empty and the queuing delay is completely eliminated. Compared to the size of the original message, that of the computing result to be transmitted is negligible, thus the time to transmit the result to the target can be ignored when comparing with to the time for computing. Fig. 2(a) illustrates the evolution of the AoI \u0001¹tºat the destination node for local computing under FCFS queuing, where gidenotes the generation time instant of the i-th status update message, t0 iis the time instant when message i-th is computed locally. When the computing is ﬁnished, the revealed status information is transmitted to the destination node. Therefore, the age drops suddenly at time t0 i, and a new message is generated at that time. 2) Remote Computing: In remote computing, zero-wait policy means that once the receiver receives a status update message, it sends an acknowledgement signal to the source node, and a new status update message will immediately be generated in the source node and be transmitted. Due to the size of the acknowledgement signal is relatively much smaller compared to that of the status update message, the feedback time is ignored. With zero-wait policy, the queuing delay for transmission is zero. The delivered status update message waits in a queue before the MEC server, and will be served with FCFS principle. Fig. 2(b) shows the change of the AoI \u0001¹tºat the destination. The i-th status update message reaches the computing queue at tiin Fig. 1(b). In accordance with zero- wait policy, the¹i+1º-th status update message starts to be transmitted at ti. Denote t0 ias the time instant for terminating service of the i-th status update message in the MEC server. 3) Partial Computing: Zero-wait strategy in partial com- puting means that the source generates a new message when the intermediate result of the previous one is received by the remote MEC server. Thus, both the local computing queue\nIEEE TRANSACTIONS ON VEHICULAR TECHNOLOGY , VOL. XX, NO. XX, XXX 2020 4 ()tD t1'g1g2 t2' t3'gn-1 tn-1' tn'gn g3g40D D1D2D3Dn-1DnQ1Q2 Q3Qn tgn+1 tn-2' (a) Local computing t1't1t2 t2' t3' t4'tn-2tn-1 tn-1'tn'tn t3t4 t0 Y2Y3T3Yn-1YnTnQ1Q2Q3 Q4Qn tΔ0Δ(t) (b) Remote computing ()tD t1't1t2 t2't3'tn-2tn-1 tn-1'tn'g10D Y1Y2T2 Dn-1Yn-1DnQ1Q2 Q3Qn t g2g3 D1D2t3 tn YnTnd1d2 t0 dn-1dn B1B2 Bn-1Bn (c) Partial computing Fig. 2. Sawtooth curve - Examples of sample path for average AoI \u0001¹tºof the three computing schemes. and the transmission queue are empty. The age evolution of partial computing is shown in Fig. 2(c). The generation time instant of the i-th message is denoted by gi, which is also the time instant ti\u00001when the¹i\u00001º-th message arrives at the remote computing queue. Denote dias the time instant when the computing of parts of the i-th message is ﬁnished at the local server. Denote t0 ias the computing completion time instant of the i-th message at the MEC server, at which time the age drops sharply. C. Average AoI Notice that local computing as well as remote computing can be viewed as special cases of partial computing. In particular, local computing can be considered as the case of partial computing with zero transmission time and zero remote computing time (or equivalently inﬁnite transmission rate andinﬁnite remote computing rate), and remote computing can be viewed as the special case with zero local computing time (inﬁnite local computing rate). Thus, we ﬁrstly calculate the average AoI for partial computing. Then, the result can be easily applied to local computing and remote computing. 1) Partial Computing: At time t, a time-stamp u¹tºdenotes the generation time of the previous processed message, and the following random process \u0001¹tºdeﬁnes the AoI of the processed status at the target node. \u0001¹tº=t\u0000u¹tº: (1) Fig. 2(c) illustrates the evolution of \u0001¹tºwith FCFS principle. Att=0, the queue is empty with \u0001¹0º=\u00010. The average age of the processed status message is the area between the curve of\u0001¹tºandt-axis in Fig. 2(c) normalized by the observed time length. The average AoI in interval ¹0; º, is \u0001 =1 ¹ 0\u0001¹tºdt: (2) Set the length of the observation interval =t0 n. The average AoI in partial computing can be represented as \u0001 =Ín i=1Qi+¹Bn+Tnº22 : (3) From Fig. 2(c), we know that Q1is a polygon, and Qi¹i\u0015 2ºis an isosceles trapezoid, which can be derived from two isosceles triangles, i.e., Qi=1 2¹Bi\u00001+Bi+Tiº2\u00001 2¹Bi+Tiº2 =TiBi\u00001+BiBi\u00001+1 2B2 i\u00001;(4) where Bi=gi+1\u0000gi=ti\u0000ti\u00001represents the inter-generation time from the i-th message to the ¹i+1º-th one at the source node. Biis also the time spent in local computing and transmission of the i-th message, i.e., Bi=Di+Yi, where Di=di\u0000girefers to the service time of the i-th message in the local server and Yi=ti\u0000didenotes the service time in the channel. Denote Ti=t0 i\u0000tias the elapsed time from the arrival time instant at the remote computing queue for the i-th status update message to the service termination time instant in the MEC server. A new representation of the average AoI in partial computing can be derived as \u0001 =˜Q +n\u00001 1 n\u00001nÕ i=2Qi; (5) where ˜Q=Q1+¹Bn+Tnº22. Note that the contribution of ˜Q to the average AoI is negligible, since when !1 , the ﬁrst term in (5) divided by tends to zero. From Fig. 2(c), we know thatt0 n=t0+Ín i=1¹Di+Yiº+Tn, then lim !1 n=E»Di+Yi¼. Thus, the inverse of the fraction to the left of the second term in (5), n\u00001, can be viewed as the sum service time of the local server and the transmission channel. Thus, the following equation is obtained lim !1 n=1 \u0016l+1 \u0016t; (6) where\u0016lis the local service rate and \u0016tis the transmission rate.\nIEEE TRANSACTIONS ON VEHICULAR TECHNOLOGY , VOL. XX, NO. XX, XXX 2020 5 Combine (4) and (5) and let increase to inﬁnity, the average AoI in partial computing can be obtained as ¯\u0001p=lim !1\u0001 =\u0016l\u0016t \u0016l+\u0016tE»Qi¼ =\u0016l\u0016t \u0016l+\u0016t\u0012 E»TiBi\u00001¼+E»BiBi\u00001¼+1 2E»B2 i\u00001¼\u0013 :(7) 2) Local Computing: Compared with partial computing, both the transmission time and the remote computing time are zero in local computing, i.e., Ti=0,Bi=Di. It is equivalent to inﬁnite transmission rate and inﬁnite remote computing rate in partial computing model, i.e., \u0016t!1 ,\u0016s!1 . Therefore, the average AoI in local computing can be obtained as follows ¯\u0001l=¯\u0001p \u0016t!1;\u0016s!1 =\u0016l\u0016t \u0016l+\u0016t\u0012 E»TiBi\u00001¼+E»BiBi\u00001¼+1 2E»B2 i\u00001¼\u0013 \u0016t!1;\u0016s!1 (8) =\u0016l\u0012 E»DiDi\u00001¼+1 2E»D2 i\u00001¼\u0013 : (9) 3) Remote Computing: Compared with partial computing, the local computing time in remote computing is zero, i.e., Bi=Yi. It is equivalent to inﬁnite local computing rate in partial computing model, i.e., \u0016l!1 . Hence, the average AoI in remote computing can be obtained as follows ¯\u0001r=¯\u0001p \u0016l!1 =\u0016l\u0016t \u0016l+\u0016t\u0012 E»TiBi\u00001¼+E»BiBi\u00001¼+1 2E»B2 i\u00001¼\u0013 \u0016l!1(10) =\u0016t\u0012 E»TiYi\u00001¼+E»YiYi\u00001¼+1 2E»Y2 i\u00001¼\u0013 : (11) Noted that for tandem queue, in the case where one or the other queue is unstable, the whole system will be unstable and the AoI will reach inﬁnity. In this paper, as we adopt zero- wait policy in the ﬁrst hop, the stability issue of the tandem queue only exists in the second hop. Therefore, as long as the service rate of the ﬁrst hop is less than that of the second hop, the tandem queue is stable. Hence, the stability issues for the three cases can be discussed as follows. For local computing, the queue is stable due to the inﬁnitely large transmission rate. For remote computing, if the remote computing rate is equal or less than the transmission rate, the tandem queue will be unstable. For partial computing, when the remote computing rate is equal or less than\u0016l\u0016t \u0016l+\u0016t, the whole system will be unstable. The calculation of equation (11) depends on the distri- butions of transmission time and computing time. In this paper, we assume exponentially distributed transmission time to indicate purely random transmission process, and derive the results for two different computing time distributions: exponential distribution [35] and deterministic distribution. The main results are detailed in the following sections. Noted that the main results are obtained based on the whole system to be stable.III. A VERAGE AOIWITH EXPONENTIALLY DISTRIBUTED COMPUTING TIME We will deduce the average age with exponentially dis- tributed computing time in this section. Exponential distri- bution is widely used to model random events in practice and can derive closed-form analytical results in most cases. For example, security based on face recognition identiﬁes the user as a random event, and users’ arrival process usually can be viewed as a Poisson process. In this section, closed-form average AoIs in the three computing schemes are presented. A. Local Computing The average AoI in local computing with exponentially distributed computing time is deﬁned as below. Theorem 1. If the local computing time is exponentially dis- tributed, the average AoI of local computing (9) is expressed as ¯\u0001l=2 \u0016l; (12) where\u0016lis the computing rate of the local server. Proof: See Appendix A. B. Remote Computing We obtain the closed-form expression of average AoI for remote computing using zero-wait policy. Both the transmis- sion time of the channel and the computing time at the MEC server are exponentially distributed. Theorem 2. Assume both the transmission time and the remote computing time are exponentially distributed. The average AoI in remote computing (11) is expressed as ¯\u0001r=1 \u0016s\u00122\u00163 t\u0000\u00162 t\u0016s+\u0016t\u00162 s \u0016s¹\u0016s+\u0016tº¹\u0016s\u0000\u0016tº+2\u0016s \u0016t+1\u0013 ; (13) where\u0016tdenotes the transmission rate and \u0016sis the comput- ing rate of the MEC server. Proof: See Appendix B. C. Partial Computing Now we derive the closed-form average AoI for partial computing under zero-wait policy. The computing time of the local server and the MEC server, as well as the transmission time of the channel are exponentially distributed. Theorem 3. Assume the local computing time, the channel transmission time and the remote computing time are expo- nentially distributed. The average AoI in partial computing (7) is obtained as ¯\u0001p=1 \u0016s+ \u00001 \u0016l\u00001+' \u0016t+\u0016l\u0016t \u0016l+\u0016t 1 \u0016l\u0016s+1 \u0016t\u0016s+2 \u00162 l +2 \u00162 t+3 \u0016l\u0016t+\u0016l\u0016t \u0016t\u0000\u0016l\u00121 ¹\u0018+\u0016lº2\u00001 ¹\u0018+\u0016tº2\u0013 \u00121 \u0018\u0000 ¹\u0016l+\u0018º+' ¹\u0016t+\u0018º\u0013\u0013 ; (14)\nIEEE TRANSACTIONS ON VEHICULAR TECHNOLOGY , VOL. XX, NO. XX, XXX 2020 6 where =\u0016t\u0016s ¹\u0016t\u0000\u0016lº¹\u0016l+\u0016sºand'=\u0016l\u0016s ¹\u0016t\u0000\u0016lº¹\u0016t+\u0016sº. The notation \u0018is expressed as \u0018=\u0016s\u0000¹\u0016l+\u0016tº+p ¹\u0016s\u0000\u0016t+\u0016lº2+4\u0016t\u0016s 2: (15) Proof: See Appendix C. It is remarkable that the average AoI for both local com- puting (12) and remote computing (13) can be obtained based on (14). Since partial computing with inﬁnite transmission rate and inﬁnite remote computing rate can be taken as local computing, while partial computing with inﬁnite local computing rate can be viewed as remote computing. Thus, we have ¯\u0001l=¯\u0001p \u0016t!1;\u0016s!1=2 \u0016l; (16) ¯\u0001r=¯\u0001p \u0016l!1=1 \u0016s\u00122\u00163 t\u0000\u00162 t\u0016s+\u0016t\u00162 s \u0016s¹\u0016s+\u0016tº¹\u0016s\u0000\u0016tº+2\u0016s \u0016t+1\u0013 :(17) As shown in Fig. 3, the analytical results of the three computing schemes with exponentially distributed computing time are validated by simulations. It must be clear that both local computing and remote computing share the same settings of\u0016l,\u0016tand\u0016s. While for partial computing, we adopt a linear computation partitioning model [21]. In particular, the computing rate of the local server, the transmission rate and the computing rate of the MEC server are denoted as \u0016l¹1\u0000 º, \u0016t ,\u0016s , respectively, and 2»0;1¼denotes the percentage of computing tasks computed by the MEC server. Particularly, =0in local computing while =1in remote computing. In Fig. 3, we set \u0016s=1and denote \u001as=\u0016t\u0016s, the optimal value of in partial computing is determined with numerical simulation methods according to the criteria of minimizing the average AoI in partial computing. In this ﬁgure, the average AoI in partial computing is smaller than local and remote computing. And when \u001as<0:1or\u001as>0:9, partial computing is signiﬁcantly better than remote computing. It can be explained as when \u001asis small, outdated message will occur due to the long transmission time in remote computing, and when\u001asis large, the MEC server will compute delayed message since the status update messages are backlogged in the computing queue. While for partial computing, it can execute a proper proportion of computing tasks required by a computation-intensive message locally to mitigate the above problems. The performance of local computing is the same as partial computing when the \u001asis small. The reason is that when the transmission rate is sufﬁciently small, partial computing prefers to compute the messages locally. As \u001as increases, the average AoI in partial computing is smaller than that in local computing, especially for a small local computing rate, such as \u0016l=0:1. IV. A VERAGE AOIWITH DETERMINISTIC COMPUTING TIME In this part, we derive the average AoI with deterministic computing time. In the application scenario where the volume of a computing task is constant and the computing resource allocated to the task is static, the computing time for an update message is deterministic. The analysis of the average AoI in Fig. 3. Comparison of the average AoI among the three computing schemes with exponentially distributed computing time under different \u0016t\u0016s. The remote computing rate is assumed as \u0016s=1. the three computing schemes with deterministic computing time is provided in the following. A. Local Computing The average AoI in local computing with deterministic computing time is given in the following theorem. Theorem 4. If the local computing time is deterministic and is equal to 1\u0016l, the average AoI for local computing (9) is expressed as ¯\u0001l=3 2\u0016l: (18) Proof: See Appendix D. B. Remote Computing With deterministic computing time, the closed-form expres- sion of average AoI for remote computing is difﬁcult to obtain. But the result can be numerically calculated based on the following theorem. Theorem 5. Assume the transmission time of the channel is exponentially distributed with mean 1\u0016tand the computing time at the MEC server is deterministic and is equal to 1\u0016s. The average AoI can be numerically computed as: ¯\u0001r=\u0016t\u0012¹1 0yiE»WijYi\u00001=yi¼fY¹yiºdyi+1 \u0016t\u0016s+2 \u00162 t\u0013 ;(19) where E»WijYi\u00001=yi¼=¹yi\u00001\u0016s 0fW¹wº¹1\u0016s 0fY¹yº¹1\u0016s\u0000yºdydw +¹1 yi\u00001\u0016sfW¹wº¹w\u0000yi+2\u0016s 0fY¹yº¹w\u0000yi+2\u0016s\u0000yºdydw;(20) where probability density function fY¹yº=\u0016te\u0000\u0016tyandfW¹wº can be obtained as the derivative of the cumulative distribution function (CDF) FW¹wº=¹1\u0000\u001aºbw\u0016scÕ k=0\u001ak k!¹k\u0000w\u0016sºke\u001a¹w\u0016s\u0000kº; (21)\nIEEE TRANSACTIONS ON VEHICULAR TECHNOLOGY , VOL. XX, NO. XX, XXX 2020 7 where\u001a=\u0016t\u0016s. Proof: See Appendix E. C. Partial Computing For partial computing, if we view the local computing process and the transmission process as a whole, the remote computing part can be considered as an GID1queuing model. If\u0016s\u0015\u0016l, a closed-form expression can be obtained. Otherwise, the average AoI can only be calculated numerically. The result is concluded in the theorem below. Theorem 6. Assume both the local computing time 1\u0016land the remote computing time 1\u0016sare deterministic, and the channel transmission time is exponentially distributed with mean 1\u0016t. If\u0016s\u0015\u0016l, the average AoI in partial computing is expressed as ¯\u0001p=1 \u0016l+\u0016t\u0012 3+3\u0016t 2\u0016l+2\u0016l \u0016t+\u0016t \u0016s+\u0016l \u0016s\u0013 : (22) For\u0016s< \u0016 l, the average AoI can be numerically computed as follows: ¯\u0001p=\u0016l\u0016t \u0016l+\u0016t ¹1 1 \u0016lE»WijBi\u00001=bi¼bifB¹biºdbi+1 \u0016s\u0016l +1 \u0016s\u0016t+3 \u0016l\u0016t+2 \u00162 l+2 \u00162 t! ; (23) where E»WijBi\u00001=bi¼=¹bi\u00001\u0016s 0fW¹wº¹ 1 \u0016s 1 \u0016lfB¹bº¹1\u0016s\u0000bºdbdw +¹1 bi\u00001\u0016sfW¹wº¹w\u0000bi+2 \u0016s 1 \u0016lfB¹bº¹w\u0000bi+2\u0016s\u0000bºdbdw;(24) where probability density function fB¹bº=\u0016te\u0000\u0016t¹b\u00001 \u0016lºand fW¹wºis the derivative of the CDF FW¹wº=¹1\u0000\u001aºbw\u0016cÕ k=0\u001ak k!¹k\u0000w\u0016ºke\u001a¹w\u0016\u0000kº; (25) where\u0016=\u0016l\u0016s \u0016l\u0000\u0016s, and\u001a=\u0016t\u0016. Proof: See Appendix F. As shown in Fig. 4, the analytical results of the three computing schemes with deterministic computing time are validated by simulations, and the remote computing rate \u0016s=1. When\u0016l=0.5, local computing and partial computing perform similar for small and large \u0016t\u0016s. The reason is that when the transmission rate \u0016tis small, the transmission time is very large; while the transmission rate is large, the computing queue at the MEC server is long. Thus, in the two cases, partial computing will process the whole computation- intensive message at the local server. While for medium value of\u0016t\u0016s, partial computing attains smaller average AoI compared with local computing due to the beneﬁt of splitting the computing task between local and remote servers. The average AoI in remote computing is always larger than partial computing, and is even larger than local computing when \u0016l= Fig. 4. Comparison of the average AoI among the three computing schemes with deterministic computing time under different \u0016t\u0016s. The remote com- puting rate is assumed as \u0016s=1. 0.5. It shows that there is no beneﬁt of using remote computing when the local computing capacity is sufﬁcient. V. N UMERICAL ANALYSIS Different parameters will inﬂuence the average AoI for computation-intensive messages in MEC systems. In this sec- tion, we study with the exponentially distributed computing time on the inﬂuence of various parameters, including message size, required number of CPU cycles, average data rate and computing capacity of the MEC server. Note that, we show the numerical results based on the stable system. For all status update messages, we adopt identical parameter pair ¹l;cº to describe the status update message, where lis the input size of the message and cindicates the required number of CPU cycles to compute the original message. The size of the transmitted data and the data rate will affect the transmission time. Note that, the transmission time refers to the total time for delivering a message over multiple channel uses. Due to channel fading, the number of bits that can be transmitted in one channel use is random. Therefore, it is reasonable to assume random transmission time for each message. The required number of CPU cycles and the computing capacity will affect the computing time. Let f1be the average local computing capacity and denote fsas the average available computing capacity of the MEC server. Denote Ras the average data rate of the channel. We adopt a linear model to represent their relationships, then the service rates \u0016l,\u0016t, \u0016scan be expressed as [21] \u0016l=f¹c;fl; º=fl ¹1\u0000 ºc; (26) \u0016t=f¹l;R; º=R l; (27) \u0016s=f¹c;fs; º=fs c: (28) Recall that 2»0;1¼denotes the percentage of computing tasks computed by the MEC server. For local computing, = 0, while for remote computing =1, and 2¹0;1ºrepresents\nIEEE TRANSACTIONS ON VEHICULAR TECHNOLOGY , VOL. XX, NO. XX, XXX 2020 8 \u0013\u0011\u0015 \u0013\u0011\u0017 \u0013\u0011\u0019 \u0013\u0011\u001b \u0014 \u0014\u0011\u0015 \u0014\u0011\u0017 \u0014\u0011\u0019 \u0014\u0011\u001b \u0015 0HVVDJH size l (Mbits) \u0014\u0013 \u0013\u0014\u0013\u0014Local computing, \u0003\u0003\u0003 c = 1000 Megacycles Remote computing, c = 1000 Megacycles Partial computing, \u0003\u0003c = 1000 Megacycles Local computing, c = 3500 Megacycles Remote computing, c = 3500 Megacycles Partial computing, \u0003\u0003c = 3500 Megacycles Average AoI Fig. 5. Average AoI versus message size partial computing scheme. For partial computing, given other parameters, is chosen to minimize the average AoI. Firstly, set R=0:5Mbits/s, fl=1GHz and fs=9 GHz. The average AoI associated with the message size l with different required number of CPU cycles cis shown in Fig. 5. It is shown that the AoI for local computing keeps stable when the message size is increasing. For remote computing, the average AoI ﬁrstly decreases sharply and then increases gradually as the message size increases with c = 3500 Megacycles. This is because the transmission rate is large with small message size, which makes a large amount of messages queued in the computing queue waiting to be computed, while for the large message size, the transmission time takes longer. When c=1000 Megacycles, there is a cross point between the curves for local computing and remote computing atl\u00190:47Mbits; meanwhile the cross point is at l\u00191:64 Mbits when c=3500 Megacycles. This phenomenon means whether remote computing is superior to local computing or not depends on the message size. With the decrease of message size, the average AoI for partial computing decreases. By properly partitioning the computing tasks between the local server and the remote server, the performance of partial computing is always better than the other two schemes with the same parameters setting. Moreover, with sufﬁciently large message size, the average AoI for partial computing is the same as local computing. This is because the larger message size will cause the longer transmission time. With the aim to reduce the average AoI, the optimal parameter in partial computing is =0, which is equivalent to local computing. Fig. 6 depicts the average AoI versus the required number of CPU cycles cwith different message sizes, where R=0:5 Mbits/s, fl=1GHz and fs=9GHz. It can be seen that the AoI curves of the three schemes rise up when the required number of CPU cycles is increasing, due to the increased computation time. There is an overlap among the curves for local computing with different message sizes because the average AoI of local computing is not affected by the message size. In general, remote computing outperforms local computing for large number of CPU cycles. However, under the condition of c\u00157000 Megacycles, the average AoI of 0 1000 2000 3000 4000 5000 6000 7000 8000 9000 Required number of CPU cycles c (Megacycles) 10 010 110 2 Local computing, \u0003\u0003\u0003 l = 0.5Mbits Remote computing, l = 0.5Mbits Partial computing, \u0003\u0003 l = 0.5Mbits Local computing, \u0003\u0003\u0003\u0003\u0003l = 1Mbits Remote computing, l = 1Mbits \u0003 Partial computing, \u0003\u0003 l = 1Mbits Local computing, \u0003\u0003\u0003\u0003l = 2Mbits \u0003 Remote computing, l = 2Mbits Partial computing, \u0003\u0003 l = 2Mbits Average AoIFig. 6. Average AoI versus required number of CPU cycles Fig. 7. Average AoI versus data rate remote computing with l=0:5Mbits boosts and performs worse than local computing. This is because as cincreases, the MEC server computes slowly which results in long queuing delay, and hence leads to large AoI. For l=1Mbits or l=2 Mbits, a sudden sharp increase of the average AoI in remote computing occurs on the larger required number of CPU cycles for the same reason. In Fig. 7, we set c=2000 Megacycles, fl=1GHz and fs=9GHz and show the AoI performance versus data rate R. Firstly, for remote computing with l=0:5Mbits, the average AoI ﬁrstly decreases with the increasing of data rate, since higher data rate leads to less transmission time. However, the average AoI increases when R\u00151:4Mbits/s. This is because the number of messages queuing at the MEC server also increases as data rate increases. For remote computing with l=1Mbits and l=2Mbits, the average AoI has the same trend as l=0:5Mbits and it increases after a certain point of larger data rate. Secondly, for partial computing, the average AoI always decreases as data rate increases. Because the transmission time reduces as data rate increases and the congestion of queuing messages at the MEC server can be alleviated by completing a part of the computing tasks locally.\nIEEE TRANSACTIONS ON VEHICULAR TECHNOLOGY , VOL. XX, NO. XX, XXX 2020 9 2000 3000 4000 5000 6000 7000 8000 Average computing capacity of the MEC server 10 010 1102 Local computing, \u0003\u0003\u0003 c = 1000 Megacycles Remote computing, c = 1000 Megacycles Partial computing, \u0003\u0003c = 1000 Megacycles Local computing, \u0003\u0003\u0003 c = 3500 Megacycles Remote computing, c = 3500 Megacycles \u0003 Partial computing, \u0003\u0003 c = 3500 Megacycles Average AoI Fig. 8. Average AoI versus average computing capacity of the MEC server Thirdly, when the data rate is small or large, the performance of local computing is superior to remote computing. This means when data rate is small or large, there’s no beneﬁt in transmitting to the MEC server for reducing the average AoI of computation-intensive messages. Finally, regardless of the data rate or the message size, partial computing always derives a smaller average AoI than the other two computing schemes. Thus it proves that partial computing outperforms both local computing and remote computing. Fig. 8 shows the impact of the computing capacity of the MEC server with data rate R=0:5Mbits/s, local computing capacity fl=1GHz and message size l=1Mbits. When c=1000 Megacycles, remote computing performs worse than local computing. This is due to the required number of CPU cycles is small, the local server can complete the computation in a short time. Under the condition of large number of required CPU cycles, such as c=3500 Megacycles, if the computing capacity is smaller than 2700, the average AoI of remote computing is larger than that of local computing, and vice versa. It eventually converges to the minimum average age ¯\u0001min=2 \u0016t. When c=1000 Megacycles, the curves for local computing and partial computing are overlapped, which indicates that local computing performs the best. When c=3500 Megacycles, with the increasing of the average computing capacity of the MEC server, the performance of partial computing converges to remote computing. Thus, it is better to ofﬂoad most of the computing task to the MEC server. VI. CONCLUSIONS We have analyzed the AoI for computation-intensive mes- sages in an MEC system with three computing strategies: local computing, remote computing and partial computing. Two computing time distributions are considered: exponential distribution and deterministic distribution. The closed-form expressions for the three computing schemes with expo- nentially distributed computing time are derived. And the average AoI with deterministic computing time is obtained numerically. Simulation results prove that partial computing has smaller average AoI than the other two computing schemes in most cases, and only in some special cases has the sameperformance as the other two schemes. The inﬂuence of various parameters for data processing on the average AoI for exponentially distributed computing time is studied by numerical results, including message size, required number of CPU cycles, data rate, and average computing capacity of the MEC server. We ﬁnd that for computation-intensive data, the combination with MEC signiﬁcantly helps to obtain the optimal AoI. For the future works, we can extend to multi source-destination pairs and consider other message generation policies. APPENDIX A PROOF OF THEOREM 1 Because the local computing time Diare independent identically distributed (iid) exponentials with E»Di¼=1\u0016l. AsDi\u00001andDiare independent, we have E»DiDi\u00001¼=¹E»Di¼º2=1\u00162 l; (29) E»D2 i\u00001¼=2\u00162 l: (30) Submit (29) and (30) into (9), the average AoI for local computing can be obtained as ¯\u0001=lim !1\u0001 =\u0016lE»Qi¼=2 \u0016l: (31) Thus, Theorem 1 can be proven. APPENDIX B PROOF OF THEOREM 2 Since the arrival process of the computing queue equals to the message’s departure process of the transmission channel. And the process is a Poisson process due to the zero-wait policy. Thus, the computing queue and an MEC server form anMM1system. Consequently, the inter-arrival time Yias well as the service time is iid exponential with E»Yi¼=1\u0016t and average service time 1\u0016s. AsYi\u00001andYiare independent, we have E»YiYi\u00001¼=¹E»Yi¼º2=1\u00162 t; (32) E»Y2 i\u00001¼=2\u00162 t: (33) Then we thoroughly calculate E»TiYi\u00001¼. For Tiof status update i, it also shows the system time in queuing theory, which has two parts as waiting time and service time, i.e., Ti=Wi+Si; (34) where Wiis the waiting time in the computing queue and Si is the service time at the MEC server. The waiting time Wi has a relation with the system time of the ¹i\u00001º-th message, Ti\u00001, and the inter-arrival time Yi. Particularly, if Ti\u00001>Yi, i.e., message iwill reach the computing queue, while the ¹i\u00001º-th message is still waiting in the queue or under service, we have Wi=Ti\u00001\u0000Yi. Otherwise, Wi=0. Thus, we can express the waiting time of message ias Wi=¹Ti\u00001\u0000Yiº+: (35) From (34), the term E»TiYi\u00001¼can be written as E»TiYi\u00001¼=E»¹Wi+SiºYi\u00001¼ =E»WiYi\u00001¼+E»SiYi\u00001¼:(36)\nIEEE TRANSACTIONS ON VEHICULAR TECHNOLOGY , VOL. XX, NO. XX, XXX 2020 10 According to (34) and (35), we can obtain the term Wi, Wi=¹Ti\u00001\u0000Yiº+=¹Wi\u00001+Si\u00001\u0000Yiº+ =¹¹Ti\u00002\u0000Yi\u00001º++Si\u00001\u0000Yiº+:(37) Notice that the system time Ti\u00002relies on the service time and the waiting time of message ¹i\u00002º, hence it is independent of Si\u00001,YiandYi\u00001. Further more, the system time Tibecomes stochastically identical, i.e., T=stTi=stTi\u00001=stTi\u00002, since the system will reach a stable state. The probability density function of the system time Tfor the MM1system is [36] fT¹tº=¹\u0016s\u0000\u0016tºe\u0000¹\u0016s\u0000\u0016tºt;t\u00150: (38) The condition expected waiting time Wigiven Yi\u00001=yican be derived as E»WijYi\u00001=yi¼=E»¹¹Ti\u00002\u0000yiº++Si\u00001\u0000Yiº+jYi\u00001=yi¼ =E»¹¹Ti\u00002\u0000yiº++Si\u00001\u0000Yiº+¼ =¹1 0fT¹tº¹1 0fS¹sº¹1 0fY¹yº\u0000¹t\u0000yiº++s\u0000y\u0001+dydsdt; =¹yi 0fT¹tº¹1 0fS¹sº¹s 0fY¹yº¹s\u0000yºdydsdt +¹1 yifT¹tº¹1 0fS¹sº¹t\u0000yi+s 0fY¹yº¹t\u0000yi+s\u0000yºdydsdt; =2\u0016t ¹\u0016s+\u0016tº¹\u0016s\u0000\u0016tºe\u0000¹\u0016s\u0000\u0016tºyi+\u0016t \u0016s¹\u0016s+\u0016tº: (39) Returning to (36), we note that the inter-arrival time Yi\u00001is independent of Si, the service time of the MEC server for the i-th message. Thus, equation (36) can be represented as E»TiYi\u00001¼=E»WiYi\u00001¼+E»Si¼E»Yi\u00001¼; (40) where E»Si¼=1 \u0016s. Further more, adopting the conditional expectation in (39), we can have equation (41) \u0000(43). E»WiYi\u00001¼=¹1 0yiE»WijYi\u00001=yi¼fYi¹yiºdyi (41) =¹1 0yi\u00122\u0016t ¹\u0016s+\u0016tº¹\u0016s\u0000\u0016tºe\u0000¹\u0016s\u0000\u0016tºyi+\u0016t \u0016s¹\u0016s+\u0016tº\u0013 \u0016te\u0000\u0016tyidyi (42) =2\u00162 t+\u00162 s\u0000\u0016t\u0016s \u00162s¹\u0016s+\u0016tº¹\u0016s\u0000\u0016tº: (43) Combine (11), (32), (33), (40) and (43), (13) is proven. APPENDIX C PROOF OF THEOREM 3 Note that the arrival process of the remote computing queue is the same process as the departure process of the tandem of the local server and the transmission channel. The time of computing at the local server or the remote server and the transmission time of channel are iid with exponentially distributed. Thus, partial computing can be viewed as an GIM1system. Three expectations in equation (7) need to be calculated for obtaining the average AoI. Since the local computing time Diand the transmission time Yiare iid exponentials with average service time 1\u0016land 1\u0016t, respectively. Thus, we can obtain the following equations E»Bi¼=E»Di+Yi¼=E»Di¼+E»Yi¼=1 \u0016l+1 \u0016t; (44)E»BiBi\u00001¼=¹E»B¼º2=1 \u00162 l+1 \u00162 t+2 \u0016l\u0016t; (45) E»B2 i\u00001¼=E»B2¼=E»¹D+Yº2¼=2 \u00162 l+2 \u00162 t+2 \u0016l\u0016t:(46) Then we calculate E»TiBi\u00001¼in detail. For status update i, Ticonsists of service time and waiting time similar to (34). The waiting time Wiis in accordance with the system time of the¹i\u00001º-th message, Ti\u00001, and the inter-arrival time Bi. Specially, if Ti\u00001>Bi, i.e., message iarrives at the remote computing queue when the ¹i\u00001º-th message is still in the queue for waiting or is under service, we can get Wi=Ti\u00001\u0000 Bi. Otherwise, Wi=0. Therefore, for message i, the waiting time can be written as Wi=¹Ti\u00001\u0000Biº+: (47) From (34), the term E»TiBi\u00001¼can be written as E»TiBi\u00001¼=E»¹Wi+SiºBi\u00001¼=E»WiBi\u00001¼+E»SiBi\u00001¼:(48) According to (34) and (47), we can obtain the term Wi, Wi=¹Ti\u00001\u0000Biº+=¹Wi\u00001+Si\u00001\u0000Biº+ =¹¹Ti\u00002\u0000Bi\u00001º++Si\u00001\u0000Biº+:(49) Note that the system time Ti\u00002depends on the service time and waiting time of message ¹i\u00002º, thus it is independent of Si\u00001,BiandBi\u00001. Further more, the system times Tibecome stochastically identical, i.e., T=stTi=stTi\u00001=stTi\u00002when the system reach a stable state. The system time T’s probability density function for the GIM1system is [37] fT¹tº=\u0016s¹1\u0000\u001bºe\u0000\u0016s¹1\u0000\u001bºt;t\u00150; (50) where\u001bsatisﬁes the following equation \u001b=b\u0003¹\u0016s\u0000\u0016s\u001bº; (51) where b\u0003¹\u0001ºis the Laplace-Stieltjes transform of random vari- able B. Forb>0, the probability density function of Biis fB¹bº:=fBi¹bº=\u0016l\u0016t \u0016t\u0000\u0016l\u0010 e\u0000\u0016lb\u0000e\u0000\u0016tb\u0011 ;b>0:(52) Then, we have b\u0003¹sº=E»exp¹\u0000sBº¼=¹1 0fB¹bºe\u0000sbdb =\u0016l\u0016t \u0016t\u0000\u0016l\u00141 s+\u0016l\u00001 s+\u0016t\u0015 :(53) Submitting (53) into (51), we can obtain the following equa- tion \u001b=b\u0003¹\u0016s\u0000\u0016s\u001bº=\u0016l\u0016t \u0016t\u0000\u0016l\u00121 \u0016s\u0000\u0016s\u001b+\u0016l\u00001 \u0016s\u0000\u0016s\u001b+\u0016t\u0013 :(54) Let\u0018=\u0016s\u0000\u0016s\u001b, we can get the expression of \u0018in equation (15) from equation (54). Therefore, the system time T’s probability density function for the GIM1system can be re-expressed as fT¹tº=\u0018e\u0000\u0018t;t\u00150: (55)\nIEEE TRANSACTIONS ON VEHICULAR TECHNOLOGY , VOL. XX, NO. XX, XXX 2020 11 We can get the condition expected waiting time Wigiven Bi\u00001=bias E»WijBi\u00001=bi¼=E»¹¹Ti\u00002\u0000biº++Si\u00001\u0000Biº+jBi\u00001=bi¼ =E»¹¹Ti\u00002\u0000biº++Si\u00001\u0000Biº+¼ =¹1 0fT¹tº¹1 0fS¹sº¹1 0fB¹bº\u0000¹t\u0000biº++s\u0000b\u0001+dbdsdt; =¹bi 0fT¹tº¹1 0fS¹sº¹s 0fB¹bº¹s\u0000bºdbdsdt +¹1 bifT¹tº¹1 0fS¹sº¹t\u0000bi+s 0fB¹bº¹t\u0000bi+s\u0000bºdbdsdt; = \u00001 \u0016l\u0000'+1 \u0016t+1 \u0016s+\u00121 \u0018\u0000 ¹\u0016l+\u0018º+' ¹\u0016t+\u0018º\u0013 e\u0000\u0018bi;(56) where =\u0016t\u0016s ¹\u0016t\u0000\u0016lº¹\u0016l+\u0016sºand'=\u0016l\u0016s ¹\u0016t\u0000\u0016lº¹\u0016t+\u0016sº. Returning to (48), be aware that the inter-arrival time Bi\u00001is independent ofSi. Therefore, (48) can be represented as E»TiBi\u00001¼=E»WiBi\u00001¼+E»Si¼E»Bi\u00001¼; (57) where E»Si¼=1 \u0016s. Then, utilizing the conditional expectation in (56), we can have equation (58) \u0000(60). E»WiBi\u00001¼=¹1 0biE»WijBi\u00001=bi¼fBi¹biºdbi (58) =¹1 0E»WijBi\u00001=bi¼bi\u0016l\u0016t \u0016t\u0000\u0016l\u0010 e\u0000\u0016lbi\u0000e\u0000\u0016tbi\u0011 dbi(59) =\u0016l+\u0016t \u0016l\u0016t\u00121 \u0016s+ \u00001 \u0016l\u0000'+1 \u0016t\u0013 +\u0016l\u0016t \u0016t\u0000\u0016l\u00121 ¹\u0018+\u0016lº2 \u00001 ¹\u0018+\u0016tº2\u0013 \u00121 \u0018\u0000 ¹\u0016l+\u0018º+' ¹\u0016t+\u0018º\u0013 : (60) Combining (7), (45), (46), (57) and (60), we derive the average AoI for partial computing in (14). Theorem 3 is proven. APPENDIX D PROOF OF THEOREM 4 Local computing with deterministic computing time means that the local computing time is constant with Di=1\u0016lfor all messages. Then, we have E»DiDi\u00001¼=DiDi\u00001=1\u00162 l; (61) E»D2 i\u00001¼=D2 i\u00001=1\u00162 l: (62) Submit (61) and (62) into (9), the average AoI for local computing with deterministic computing time can be obtained as ¯\u0001=lim !1\u0001 =\u0016lE»Qi¼=3 2\u0016l: (63) APPENDIX E PROOF OF THEOREM 5 Be aware that the arrival process of the computing queue is equals to the messages departure process of the transmission channel, which is a Poisson process when utilizing zero-wait policy. And the computing time is deterministic. Thus, the computing queue and the MEC server form an MD1system. In this queuing system, the inter-arrival time Yiis iid, andfollows exponential distribution with mean E»Yi¼=1\u0016tand the deterministic service time is Si=1\u0016s. We now calculate E»TiYi\u00001¼in detail. For status update i,Tihas two parts as waiting time and service time, i.e., Ti=Wi+Si=Wi+1 \u0016s: (64) From (64), the term E»TiYi\u00001¼can be written as E»TiYi\u00001¼=E»¹Wi+SiºYi\u00001¼ =E»WiYi\u00001¼+E»Yi\u00001¼ \u0016s: (65) According to (64) and (35), we can obtain the term Wi, Wi=¹Ti\u00001\u0000Yiº+=¹Wi\u00001+1 \u0016s\u0000Yiº+ =\u0012 ¹Ti\u00002\u0000Yi\u00001º++1 \u0016s\u0000Yi\u0013+ =\u0012 ¹Wi\u00002+1 \u0016s\u0000Yi\u00001º++1 \u0016s\u0000Yi\u0013+ : (66) Since Wi\u00002andYi\u00001are independent with each other, the conditional expected waiting time Wigiven Yi\u00001=yican be obtained as E»WijYi\u00001=yi¼ =E»¹¹Wi\u00002+1 \u0016s\u0000Yi\u00001º++1 \u0016s\u0000Yiº+ Yi\u00001=yi¼ (67) =E»¹¹Wi\u00002+1 \u0016s\u0000yiº++1 \u0016s\u0000Yiº+¼ =¹1 0fW¹wº¹1 0fY¹yº\u0012 ¹w+1 \u0016s\u0000yiº++1 \u0016s\u0000y\u0013+ dydw; =¹yi\u00001\u0016s 0fW¹wº¹1\u0016s 0fY¹yº¹1\u0016s\u0000yºdydw+ ¹1 yi\u00001\u0016sfW¹wº¹w\u0000yi+2\u0016s 0fY¹yº¹w\u0000yi+2\u0016s\u0000yºdydw;(68) where fW¹wºis the probability density function of the waiting time Win an MD1queuing system which is obtained as the derivative of the CDF (see [38]) FW¹wº=¹1\u0000\u001aºbw\u0016scÕ k=0\u001ak k!¹k\u0000w\u0016sºke\u001a¹w\u0016s\u0000kº; (69) where\u001a=\u0016t\u0016s. Utilizing the conditional expectation E»WijYi\u00001=yi¼in (68), we can obtain E»WiYi\u00001¼through the equation (41). Having calculated E»WiYi\u00001¼, we can combine (11), (32), (33) and (65) to obtain the average AoI in remote computing with deterministic computing time. APPENDIX F PROOF OF THEOREM 6 Note that the arrival process of the remote computing queue is the same process as the departure process of the tandem of the local server and the transmission channel. The time of computing at the local server and the remote server are deterministic, while the transmission time of channel is exponentially distributed. Thus, partial computing can be\nIEEE TRANSACTIONS ON VEHICULAR TECHNOLOGY , VOL. XX, NO. XX, XXX 2020 12 viewed as an GID1system. To derive the average AoI, three expectations need to be calculated in equation (7). As the local computing time Di=1\u0016lis constant and the transmission time Yiis iid, and follows exponential distribution with average service time 1\u0016t, we can obtain the following equations E»Bi¼=E»Di+Yi¼=E»1 \u0016l+Yi¼=1 \u0016l+1 \u0016t; (70) E»BiBi\u00001¼=E»¹1 \u0016l+Yiº¹1 \u0016l+Yi\u00001º¼=1 \u00162 l+1 \u00162 t+2 \u0016l\u0016t;(71) E»B2 i\u00001¼=E»¹1 \u0016l+Yiº2¼=1 \u00162 l+2 \u00162 t+2 \u0016l\u0016t: (72) Then, we need to calculate E»TiBi\u00001¼. The term E»TiBi\u00001¼is the same as (48). E»WiBi\u00001¼need to be calculated to obtain the average AoI. The probability density function of Biis fB¹bº:=fBi¹bº=\u0016te\u0000\u0016t¹b\u00001 \u0016lº;b\u00151 \u0016l: (73) The MEC service time is constant with1 \u0016s. There is no queueing when1 \u0016l\u00151 \u0016s, since the MEC computing time is smaller than the inter-arrival time. Thus, the waiting time is zero. Accordingly, this term E»WiBi\u00001¼=0. Therefore, in the case of1 \u0016l\u00151 \u0016s, combining (7), (57), and (70) \u0000(72), we can obtain the average AoI in partial computing as ¯\u0001p=\u0016l\u0016t \u0016l+\u0016t\u0012 E»Si¼E»Bi\u00001¼+E»BiBi\u00001¼+1 2E»B2 i\u00001¼\u0013 =1 \u0016l+\u0016t\u0012 3+3\u0016t 2\u0016l+2\u0016l \u0016t+\u0016t \u0016s+\u0016l \u0016s\u0013 :(74) Then we calculate E»WiBi\u00001¼when1 \u0016l<1 \u0016s. For status update i,Ticomprises the waiting time and service time. According to the equation (34) and (47), we express the waiting time of thei-th message as Wi=¹Ti\u00001\u0000Biº+=¹Wi\u00001+1\u0016s\u0000Biº+ =¹¹Wi\u00002+1\u0016s\u0000Bi\u00001º++1\u0016s\u0000Biº+: (75) The conditional expected waiting time Wigiven Bi\u00001=bican be obtained as E»WijBi\u00001=bi¼ =E»¹¹Wi\u00002+1\u0016s\u0000Bi\u00001º++1\u0016s\u0000Biº+jBi\u00001=bi¼ (76) =E»¹¹Wi\u00002+1\u0016s\u0000biº++1\u0016s\u0000Biº+¼ =¹1 0fW¹wº¹1 1 \u0016lfB¹bº\u0000¹w+1\u0016s\u0000biº++1\u0016s\u0000b\u0001+dbdw; =¹bi\u00001\u0016s 0fW¹wº¹ 1 \u0016s 1 \u0016lfB¹bº¹1\u0016s\u0000bºdbdw+ ¹1 bi\u00001\u0016sfW¹wº¹w\u0000bi+2 \u0016s 1 \u0016lfB¹bº¹w\u0000bi+2\u0016s\u0000bºdbdw;(77) where fW¹wºis the probability density function of the waiting time Win the GID1queue system. As the inter-arrival time is1\u0016lplus an exponentially distributed random variable while the service time is a constant 1\u0016s, the waiting time of thisGID1system is the same as that of an MD1system with arrival rate \u0016tand deterministic service rate \u0016=1 1\u0016s\u00001\u0016l= \u0016l\u0016s \u0016l\u0000\u0016s. Therefore, fW¹wºcan be obtained as the derivative of the CDF refer to the MD1system FW¹wº=¹1\u0000\u001aºbw\u0016cÕ k=0\u001ak k!¹k\u0000w\u0016ºke\u001a¹w\u0016\u0000kº; (78) where\u001a=\u0016t\u0016. Returning to (48), we note that the inter- arrival time Bi\u00001is independent of Si. Therefore, (48) can be rewritten as (57) with E»Si¼=1 \u0016s. Moreover, utilizing the conditional expectation in (77), E»WiBi\u00001¼can be calculated numerically according to (80). Having calculated E»WiBi\u00001¼, we can calculate the average AoI combining (7), (57), and (70)\u0000(72). E»WiBi\u00001¼=¹1 1 \u0016lbiE»WijBi\u00001=bi¼fBi¹biºdbi (79) =¹1 1 \u0016lE»WijBi\u00001=bi¼bi\u0016te\u0000\u0016t¹bi\u00001 \u0016lºdbi:(80) REFERENCES [1] Q. Kuang, J. Gong, X. Chen, and X. Ma, “Age-of-information for computation-intensive messages in mobile edge computing,” in 2019 11th Int. Conf. Wireless Commun. Signal Process. (WCSP) , Oct. 2019, pp. 1–6. [2] S. Kaul, M. Gruteser, V . Rai, and J. Kenney, “Minimizing age of information in vehicular networks,” in Proc. SECON , Jun. 2011, pp. 350–358. [3] S. Kaul, R. Yates, and M. Gruteser, “Real-time status: How often should one update?” in Proc. IEEE Int. Conf. Comput. Commun. (INFOCOM) , Orlando, FL, 2012, pp. 2731–2735. [4] R. D. Yates. and S. Kaul, “Real-time status updating: Multiple sources,” inIEEE Int. Symp. Inf. Theory (ISIT) , Cambridge, MA, 2012, pp. 2666– 2670. [5] A. M. Bedewy, Y . Sun, and N. B. Shroff, “The age of information in multihop networks,” in IEEE Int. Symp. Inf. Theory (ISIT) , Jun. 2017, pp. 576–580. [6] R. Talak, S. Karaman, and E. Modiano, “Minimizing age-of-information in multi-hop wireless networks,” in Proc. Allerton , Monticello, IL, 2017, pp. 486–493. [7] R. D. Yates, “Lazy is timely: Status updates by an energy harvesting source,” in Proc. IEEE ISIT , Jun 2015, p. 30083012. [8] Y . Sun, E. Uysal-Biyikoglu, R. D. Yates, C. E. Koksal, and N. B. Shroff, “Update or wait: How to keep your data fresh,” IEEE Trans. Inf. Theory , vol. 63, no. 11, pp. 7492–7508, Nov. 2017. [9] L. Kleinrock, Queueing Systems . New York, NY , USA: Wiley, 1975. [10] M. Costa, M. Codreanu, and A. Ephremides, “On the age of information in status update systems with packet management,” IEEE Trans. Inf. Theory , vol. 62, no. 4, pp. 1897–1910, 2016. [11] R. D. Yates, “Age of information in a network of preemptive servers,” inProc. IEEE Int. Conf. Comput. Commun. (INFOCOM) , Apr. 2018. [12] ——, “The age of information in networks: Moments, distributions, and sampling,” arXiv preprint arXiv:1806.03487 , 2018. [13] Y . Mao, C. You, J. Zhang, K. Huang, and K. B. Letaief, “A survey on mobile edge computing: The communication perspective,” IEEE Commun. Surveys Tuts. , vol. 19, no. 4, pp. 2322–2358, 4th Quart., 2017. [14] P. Mach and Z. Becvar, “Mobile edge computing: A survey on architec- ture and computation ofﬂoading,” IEEE Commun. Surveys Tuts. , vol. 19, no. 3, pp. 16281656, 3rd Quart., 2017. [15] Y . Zhang, H. Liu, L. Jiao, and X. Fu, “To ofﬂoad or not to ofﬂoad: An efﬁcient code partition algorithm for mobile cloud computing,” in Proc. 1st IEEE Int. Conf. Cloud Netw. (CLOUDNET) , Paris, 2012, pp. 80–86. [16] J. Liu, Y . Mao, J. Zhang, and K. B. Letaief, “Delay-optimal computation task scheduling for mobile-edge computing systems,” in Proc. IEEE Int. Symp. Inf. Theory (ISIT) , Barcelona, Spain, 2016, p. 14511455. [17] Y . Mao, J. Zhang, and K. B. Letaief, “Dynamic computation ofﬂoading for mobile-edge computing with energy harvesting devices,” IEEE J. Sel. Areas Commun. , vol. 34, no. 12, p. 35903605, Dec. 2016. [18] L. Zhao, J. Wang, J. Liu, and N. Kato, “Optimal edge resource allocation in iot-based smart cities,” IEEE Netw. , vol. 33, no. 2, pp. 30–35, 2019.\nIEEE TRANSACTIONS ON VEHICULAR TECHNOLOGY , VOL. XX, NO. XX, XXX 2020 13 [19] J. Ren, G. Yu, Y . He, and G. Y . Li, “Collaborative cloud and edge computing for latency minimization,” IEEE Trans. Veh. Technol. , vol. 68, no. 5, pp. 5031–5044, 2019. [20] S. Sardellitti, G. Scutari, and S. Barbarossa, “Joint optimization of radio and computational resources for multicell mobile-edge computing,” IEEE Trans. Signal Inf. Process. Netw. , vol. 1, no. 2, pp. 89–103, 2015. [21] Y . Wang, M. Sheng, X. Wang, L. Wang, and J. Li, “Mobile-edge com- puting: Partial computation ofﬂoading using dynamic voltage scaling,” IEEE Trans. Commun. , vol. 64, no. 10, pp. 4268–4282, 2016. [22] C. You, K. Huang, H. Chae, and B. Kim, “Energy-efﬁcient resource al- location for mobile-edge computation ofﬂoading,” IEEE Trans. Wireless Commun. , vol. 16, no. 3, pp. 1397–1411, 2017. [23] F. Wang, J. Xu, X. Wang, and S. Cui, “Joint ofﬂoading and computing optimization in wireless powered mobile-edge computing systems,” IEEE Trans. Wireless Commun. , vol. 17, no. 3, pp. 1784–1797, 2018. [24] T. G. Rodrigues, K. Suto, H. Nishiyama, N. Kato, and K. Temma, “Cloudlets activation scheme for scalable mobile edge computing with transmission power control and virtual machine migration,” IEEE Trans. Comput. , vol. 67, no. 9, pp. 1287–1300, 2018. [25] O. Muoz, A. Pascual-Iserte, and J. Vidal, “Optimization of radio and computational resources for energy efﬁciency in latency-constrained application ofﬂoading,” IEEE Trans. Veh. Technol. , vol. 64, no. 10, pp. 4738–4755, 2015. [26] X. Chen, L. Jiao, W. Li, and X. Fu, “Efﬁcient multi-user computation ofﬂoading for mobile-edge cloud computing,” IEEE/ACM Trans. Netw. , vol. 24, no. 5, pp. 2795–2808, 2016. [27] T. Q. Dinh, J. Tang, Q. D. La, and T. Q. S. Quek, “Ofﬂoading in mobile edge computing: Task allocation and computational frequency scaling,” IEEE Trans. Commun. , vol. 65, no. 8, pp. 3571–3584, 2017. [28] B. Zhou and W. Saad, “Optimal sampling and updating for minimizing age of information in the internet of things,” in IEEE Global Commun. Conf. (GLOBECOM) , 2018. [29] P. Zou, O. Ozel, and S. Subramaniam, “Trading off computation with transmission in status update systems,” arXiv preprint arXiv:1907.00928 , 2019. [30] A. Alabbasi and V . Aggarwal, “Joint information freshness and com- pletion time optimization for vehicular networks,” arXiv preprint arXiv:1811.12924 , 2018. [31] Y . Dong, Z. Chen, and P. Fan, “Timely two-way data exchanging in unilaterally powered fog computing systems,” IEEE Access , vol. 7, pp. 21 103–21 117, 2019. [32] J. Zhong, W. Zhang, R. D. Yates, A. Garnaev, and Y . Zhang, “Age of information in a network of preemptive servers,” in Proc. IEEE Int. Conf. Comput. Commun. (INFOCOM) , Paris, France, 2019, pp. 674–679. [33] A. Arafa, R. D. Yates, and H. V . Poor, “Timely cloud computing: Preemption and waiting,” arXiv preprint arXiv:1907.05408 , 2019. [34] X. Song, X. Qin, Y . Tao, B. Liu, and P. Zhang, “Age based task schedul- ing and computation ofﬂoading in mobile-edge computing systems,” arXiv preprint arXiv:1905.11570 , 2019. [35] S. Sthapit, J. Thompson, N. M. Robertson, and J. R. Hopgood, “Compu- tational load balancing on the edge in absence of cloud and fog,” IEEE Trans. Mobile Comput. , vol. 18, no. 7, pp. 1499–1512, 2019. [36] A. Papoulis and S. U. Pillai, Probability, Random Variables and Stochas- tic Processes with Errata Sheet . McGraw-Hill, Dec. 2001. [37] J. Sztrik, Basic queueing theory . University of Debrecen: Faculty of Informatics, 2011. [38] G. J. Franx, “A simple solution for the m/d/c waiting time distribution,” Operations Research Letters , vol. 29, pp. 221–229, 2001.\n",
  "metadata": {
    "paper_id": "2002.06400v1",
    "downloaded_at": "2025-08-24T21:32:19.842065+00:00"
  },
  "processed_at": "2025-08-24T21:32:19.842083+00:00"
}